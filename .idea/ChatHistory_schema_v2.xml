<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChatHistoryState">
    <option name="serializedSessions">
      <map>
        <entry key="0ed78732-d0d8-49c7-b9b1-69b023d5a247" value="{&quot;id&quot;:&quot;0ed78732-d0d8-49c7-b9b1-69b023d5a247&quot;,&quot;name&quot;:&quot;Code Explanation Request&quot;,&quot;timestamp&quot;:1740916379420,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nexplain code\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;This code implements a POP3 (Post Office Protocol version 3) email client in Go. Here\u0027s a high-level breakdown of its main components and functionality:\n\n### Main Components\n\n1. **POP3Client Struct**\n```go\ntype POP3Client struct {\n    cfg    *types.Config\n    logger *slog.Logger\n}\n```\n- Basic client structure holding configuration and logging capabilities\n\n2. **MIME Type Mapping**\n- Comprehensive map (`mimeToExt`) of MIME types to file extensions\n- Used for proper file extension assignment when saving attachments\n\n### Key Functions\n\n1. **Connect Function**\n- Establishes connection to POP3 server\n- Handles TLS configuration\n- Performs authentication\n- Includes secure password logging (obfuscated)\n\n2. **DownloadEmails Function**\n- Main workflow for downloading emails\n- Features:\n  - Tracking of downloaded emails\n  - Error logging\n  - Attachment processing\n  - Email parsing\n  - Message deletion (optional)\n\n3. **Content Processing Functions**\n- `decodeContent`: Handles different email content encodings (base64, quoted-printable)\n- `extractAttachmentsMultipart`: Processes multipart email messages to extract attachments\n- `generateUniqueMessageID`: Creates unique identifiers for messages\n\n### Key Features\n\n1. **Security**\n- TLS support\n- Password obfuscation in logs\n- Certificate verification options\n\n2. **Robust Error Handling**\n- Comprehensive error logging\n- Graceful failure handling\n- Detailed error tracking\n\n3. **Attachment Processing**\n- MIME type detection\n- File name sanitization\n- Size limitations\n- Allowed file type filtering\n\n4. **Email Tracking**\n- Prevents duplicate downloads\n- Tracks successful downloads\n- Maintains download history\n\n5. **Configuration Options**\n- Configurable deletion after download\n- Flexible attachment storage options\n- Customizable security settings\n\nThis implementation provides a robust solution for downloading emails and attachments via POP3, with strong emphasis on error handling, security, and configurability.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\nconfig/templates/base.yaml\n```yaml:config/templates/base.yaml\n# Base template for email extractor configurations\nmeta:\n  id: \&quot;base\&quot;\n  name: \&quot;Base Template\&quot;\n  description: \&quot;Base template for email extraction configuration\&quot;\n  template: \&quot;\&quot;\n  enabled: true\n\nserver:\n  port: 8080\n  host: \&quot;0.0.0.0\&quot;\n  read_timeout: 30\n  write_timeout: 30\n  idle_timeout: 60\n\nemail:\n  default_timeout: 300\n  rate_limit: 100\n  max_concurrent: 5\n  protocols:\n    imap:\n      enabled: false\n      default_port: 993\n      insecure_port: 143\n      idle_timeout: 60\n      batch_size: 100\n      server: \&quot;${IMAP_SERVER}\&quot;\n      username: \&quot;${IMAP_USERNAME}\&quot;\n      password: \&quot;${IMAP_PASSWORD}\&quot;\n      folders: [\&quot;INBOX\&quot;]\n      use_idle: false\n      delete_after_download: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n          cert_file: \&quot;\&quot;\n          key_file: \&quot;\&quot;\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n          client_id: \&quot;${OAUTH_CLIENT_ID}\&quot;\n          client_secret: \&quot;${OAUTH_CLIENT_SECRET}\&quot;\n    pop3:\n      enabled: false\n      default_port: 995\n      insecure_port: 110\n      server: \&quot;${POP3_SERVER}\&quot;\n      username: \&quot;${POP3_USERNAME}\&quot;\n      password: \&quot;${POP3_PASSWORD}\&quot;\n      delete_after_download: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n          cert_file: \&quot;\&quot;\n          key_file: \&quot;\&quot;\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n          client_id: \&quot;${OAUTH_CLIENT_ID}\&quot;\n          client_secret: \&quot;${OAUTH_CLIENT_SECRET}\&quot;\n  retry:\n    max_attempts: 3\n    delay: 5\n  attachments:\n    allowed_types:\n      - \&quot;.pdf\&quot;\n      - \&quot;.xml\&quot;\n      - \&quot;.xlsx\&quot;\n      - \&quot;.xls\&quot;\n      - \&quot;.doc\&quot;\n      - \&quot;.docx\&quot;\n      - \&quot;.txt\&quot;\n      - \&quot;.csv\&quot;\n    max_size: 104857600\n    storage_path: \&quot;/home/stefan/data/attachments/${YYYY}/${MM}/${DD}\&quot;\n    naming_pattern: \&quot;${unixtime}_${filename}\&quot;\n    preserve_structure: true\n    scan_nested: true\n    sanitize_filenames: true\n    handle_duplicates: \&quot;increment\&quot;\n  tracking:\n    enabled: false\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/data/tracking\&quot;\n    retention_days: 30\n    tracking_format: \&quot;json\&quot;\n    track_downloaded: true\n  error_logging:\n    enabled: true\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/data/error_logs\&quot;\n    retention_days: 30\n    log_raw_message: false\n\nsecurity:\n  allowed_ips:\n    - \&quot;127.0.0.1\&quot;\n    - \&quot;::1\&quot;\n  api_keys: []\n  cors:\n    enabled: true\n    allowed_origins:\n      - \&quot;http://localhost:3000\&quot;\n    allowed_methods:\n      - \&quot;GET\&quot;\n      - \&quot;POST\&quot;\n      - \&quot;PUT\&quot;\n      - \&quot;DELETE\&quot;\n    allowed_headers:\n      - \&quot;Authorization\&quot;\n      - \&quot;Content-Type\&quot;\n    expose_headers:\n      - \&quot;X-Request-ID\&quot;\n    max_age: 3600\n    allow_credentials: true\n  rate_limiting:\n    enabled: true\n    requests_per_second: 10\n    burst: 50\n\nlogging:\n  level: \&quot;info\&quot;\n  format: \&quot;json\&quot;\n  output: \&quot;stdout\&quot;\n  file_path: \&quot;${LOG_FILE_PATH}\&quot;\n  include_caller: true\n  redact_sensitive: true\n  rotation:\n    enabled: true\n    max_size: 100\n    max_age: 30\n    max_backups: 5\n    compress: true\n\nmonitoring:\n  metrics_enabled: true\n  metrics_path: \&quot;/metrics\&quot;\n  health_check_path: \&quot;/health\&quot;\n  tracing:\n    enabled: true\n    exporter: \&quot;jaeger\&quot;\n    endpoint: \&quot;${JAEGER_ENDPOINT}\&quot;\n    sample_rate: 0.1\n  profiling:\n    enabled: true\n    path: \&quot;/debug/pprof\&quot;\n  alerts:\n    enabled: true\n    endpoints:\n      - type: \&quot;email\&quot;\n        address: \&quot;${ALERT_EMAIL}\&quot;\n    thresholds:\n      error_rate: 0.01\n      response_time_ms: 1000\n      disk_usage_percent: 90\n\nscheduling:\n  enabled: true\n  frequency_every: \&quot;minute\&quot;\n  frequency_amount: 3\n  start_now: true\n  start_at: \&quot;2024-03-15T00:00:00Z\&quot;  # RFC3339 format\n  stop_at: \&quot;2025-12-31T23:59:59Z\&quot;   # RFC3339 format \n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\nconfig/config.yaml\n```yaml:config/config.yaml\nserver:\n  port: 8080\n  host: \&quot;0.0.0.0\&quot;\n  read_timeout: 30\n  write_timeout: 30\n  idle_timeout: 60\n\nemail:\n  default_timeout: 300  # seconds\n  rate_limit: 100      # requests per minute\n  max_concurrent: 5    # maximum concurrent downloads\n  protocols:\n    imap:\n      enabled: true\n      default_port: 993  # Default SSL/TLS port\n      insecure_port: 143  # Non-SSL port\n      idle_timeout: 60  # IMAP IDLE timeout\n      batch_size: 100  # Number of emails to fetch per batch\n    pop3:\n      enabled: true\n      default_port: 995  # Default SSL/TLS port\n      insecure_port: 110  # Non-SSL port\n      delete_after_download: false\n  security:\n    tls:\n      enabled: true\n      min_version: \&quot;1.2\&quot;\n      verify_cert: true\n      cert_file: \&quot;\&quot;  # Optional client certificate\n      key_file: \&quot;\&quot;   # Optional client key\n    oauth2:\n      enabled: false\n      providers:\n        google:\n          client_id: \&quot;\&quot;\n          client_secret: \&quot;\&quot;\n          redirect_url: \&quot;http://localhost:8080/auth/callback\&quot;\n          auth_url: \&quot;https://accounts.google.com/o/oauth2/auth\&quot;\n          token_url: \&quot;https://oauth2.googleapis.com/token\&quot;\n          scopes:\n            - \&quot;https://mail.google.com/\&quot;\n        microsoft:\n          client_id: \&quot;\&quot;\n          client_secret: \&quot;\&quot;\n          redirect_url: \&quot;http://localhost:8080/auth/callback\&quot;\n          auth_url: \&quot;https://login.microsoftonline.com/common/oauth2/v2.0/authorize\&quot;\n          token_url: \&quot;https://login.microsoftonline.com/common/oauth2/v2.0/token\&quot;\n          scopes:\n            - \&quot;https://outlook.office.com/IMAP.AccessAsUser.All\&quot;\n            - \&quot;https://outlook.office.com/POP.AccessAsUser.All\&quot;\n            - \&quot;offline_access\&quot;\n  retry:\n    max_attempts: 3\n    delay: 5          # seconds between retries\n  attachments:\n    allowed_types:\n      - \&quot;.pdf\&quot;\n      - \&quot;.docx\&quot;\n      - \&quot;.xlsx\&quot;\n      - \&quot;.zip\&quot;\n      - \&quot;.jpg\&quot;\n      - \&quot;.jpeg\&quot;\n      - \&quot;.png\&quot;\n      - \&quot;.txt\&quot;\n      - \&quot;.csv\&quot;\n    max_size: 26214400  # 25MB in bytes\n    storage_path: \&quot;/data/attachments\&quot;\n    naming_pattern: \&quot;${date}_${filename}\&quot;  # supports variables: date, filename, messageId\n    preserve_structure: true  # maintain folder structure from email\n    scan_nested: true  # scan inside zip files for attachments\n    sanitize_filenames: true # remove potentially dangerous characters\n\nsecurity:\n  allowed_ips:\n    - \&quot;127.0.0.1\&quot;\n    - \&quot;::1\&quot;\n  api_keys:\n    - \&quot;test-key-1\&quot;\n    - \&quot;test-key-2\&quot;\n  cors:\n    enabled: true\n    allowed_origins:\n      - \&quot;http://localhost:3000\&quot;\n      - \&quot;https://yourdomain.com\&quot;\n    allowed_methods:\n      - \&quot;GET\&quot;\n      - \&quot;POST\&quot;\n      - \&quot;PUT\&quot;\n      - \&quot;DELETE\&quot;\n\nlogging:\n  level: \&quot;info\&quot;  # debug, info, warn, error\n  format: \&quot;json\&quot;\n  output: \&quot;stdout\&quot;  # stdout, file\n  file_path: \&quot;/var/log/email-extractor.log\&quot;\n  include_caller: true\n  redact_sensitive: true  # redact passwords and tokens in logs\n\nmonitoring:\n  metrics_enabled: true\n  metrics_path: \&quot;/metrics\&quot;\n  health_check_path: \&quot;/health\&quot;\n  tracing:\n    enabled: true\n    exporter: \&quot;jaeger\&quot;\n    endpoint: \&quot;http://jaeger:14268/api/traces\&quot; \n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\nconfig/default.config.yaml\n```yaml:config/default.config.yaml\nmeta:\n  id: \&quot;default\&quot;\n  name: \&quot;Default Configuration\&quot;\n  description: \&quot;Default email extraction configuration changed\&quot;\n  template: \&quot;base\&quot;\n  enabled: true\n\nserver:\n  port: 8080\n  host: \&quot;0.0.0.0\&quot;\n  read_timeout: 30\n  write_timeout: 30\n  idle_timeout: 60\n\nemail:\n  default_timeout: 300\n  rate_limit: 100\n  max_concurrent: 5\n  protocols:\n    imap:\n      enabled: true\n      default_port: 143\n      insecure_port: 143\n      idle_timeout: 60\n      batch_size: 100\n      server: \&quot;imap.mail.hostpoint.ch\&quot;\n      username: \&quot;test@cpaas.pro\&quot;\n      password: \&quot;99#Tuew201515\&quot;\n      folders: [\&quot;INBOX\&quot;]\n      use_idle: false\n      delete_after_download: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n    pop3:\n      enabled: false\n      default_port: 995\n      insecure_port: 110\n      server: \&quot;email-ssl.com.br\&quot;  # Example for Gmail POP3\n      username: \&quot;ah@ecogotas.com.br\&quot; #\&quot;${POP3_USERNAME}\&quot;  # Will be replaced with environment variable\n      password: \&quot;H4ld3m4nn76@!\&quot; #\&quot;${POP3_PASSWORD}\&quot;  # Will be replaced with environment variable\n      delete_after_download: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n  retry:\n    max_attempts: 3\n    delay: 5\n  attachments:\n    allowed_types:\n      - \&quot;.jpg\&quot;\n      - \&quot;.jpeg\&quot;\n      - \&quot;.png\&quot;\n      - \&quot;.gif\&quot;\n      - \&quot;.pdf\&quot;\n      - \&quot;.xml\&quot;\n      - \&quot;.xlsx\&quot;\n      - \&quot;.xls\&quot;\n      - \&quot;.doc\&quot;\n      - \&quot;.docx\&quot;\n      - \&quot;.ppt\&quot;\n      - \&quot;.pptx\&quot;\n      - \&quot;.txt\&quot;\n      - \&quot;.csv\&quot;\n      - \&quot;.zip\&quot;\n      - \&quot;.rar\&quot;\n      - \&quot;.7z\&quot;\n      - \&quot;.rtf\&quot;\n    max_size: 104857600  # 100MB in bytes\n    storage_path: \&quot;/home/stefan/data/attachments/${account}_${YYYY}_${MM}_${DD}\&quot;\n    naming_pattern: \&quot;${unixtime}_${filename}\&quot;\n    preserve_structure: true\n    scan_nested: true\n    sanitize_filenames: true\n    handle_duplicates: \&quot;increment\&quot;\n  tracking:\n    enabled: false\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/home/stefan/data/tracking\&quot;\n    retention_days: 30\n    tracking_format: \&quot;json\&quot;\n  error_logging:\n    enabled: true\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/home/stefan/data/error_logs\&quot;\n    retention_days: 30\n    log_raw_message: false\nsecurity:\n  allowed_ips:\n    - \&quot;127.0.0.1\&quot;\n    - \&quot;::1\&quot;\n  api_keys:\n    - \&quot;test-key-1234567890abcdef\&quot;\n  cors:\n    enabled: true\n    allowed_origins:\n      - \&quot;http://localhost:3000\&quot;\n    allowed_methods:\n      - \&quot;GET\&quot;\n      - \&quot;POST\&quot;\n      - \&quot;PUT\&quot;\n      - \&quot;DELETE\&quot;\n    allowed_headers:\n      - \&quot;Authorization\&quot;\n      - \&quot;Content-Type\&quot;\n    expose_headers:\n      - \&quot;X-Request-ID\&quot;\n    max_age: 3600\n    allow_credentials: true\n  rate_limiting:\n    enabled: true\n    requests_per_second: 10\n    burst: 50\n\nlogging:\n  level: \&quot;debug\&quot;  # debug, info, warn, error\n  format: \&quot;text\&quot; # json, text\n  output: \&quot;stdout\&quot;  # stdout, file\n  file_path: \&quot;/var/log/email-extractor.log\&quot;\n  include_caller: true\n  redact_sensitive: true\n  rotation:\n    enabled: true\n    max_size: 100  # MB\n    max_age: 30    # days\n    max_backups: 5\n    compress: true\n\nmonitoring:\n  metrics_enabled: true\n  metrics_path: \&quot;/metrics\&quot;\n  health_check_path: \&quot;/health\&quot;\n  tracing:\n    enabled: true\n    exporter: \&quot;jaeger\&quot;\n    endpoint: \&quot;http://jaeger:14268/api/traces\&quot;\n    sample_rate: 0.1\n  profiling:\n    enabled: true\n    path: \&quot;/debug/pprof\&quot;\n  alerts:\n    enabled: true\n    endpoints:\n      - type: \&quot;email\&quot;\n        address: \&quot;alerts@example.com\&quot;\n    thresholds:\n      error_rate: 0.01\n      response_time_ms: 1000\n      disk_usage_percent: 90\n\nscheduling:\n  enabled: true\n  frequency_every: \&quot;minute\&quot;\n  frequency_amount: 3\n  start_now: true\n  start_at: \&quot;2024-03-15T00:00:00Z\&quot;\n  stop_at: \&quot;2025-12-31T23:59:59Z\&quot;\n\n# ... rest of the configuration remains the same ... \n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\nconfig/default.config.yaml.template\n```plain_text:config/default.config.yaml.template\nmeta:\n  id: \&quot;default\&quot;\n  name: \&quot;Default Configuration\&quot;\n  description: \&quot;Default email extraction configuration changed\&quot;\n  template: \&quot;base\&quot;\n  enabled: true\n\nserver:\n  port: 8080\n  host: \&quot;0.0.0.0\&quot;\n  read_timeout: 30\n  write_timeout: 30\n  idle_timeout: 60\n\nemail:\n  default_timeout: 300\n  rate_limit: 100\n  max_concurrent: 5\n  protocols:\n    imap:\n      enabled: false\n      default_port: 993\n      insecure_port: 143\n      idle_timeout: 60\n      batch_size: 100\n      server: \&quot;${IMAP_SERVER}\&quot;\n      username: \&quot;${IMAP_USERNAME}\&quot;\n      password: \&quot;${IMAP_PASSWORD}\&quot;\n      folders: [\&quot;INBOX\&quot;]\n      use_idle: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n    pop3:\n      enabled: true\n      default_port: 995\n      insecure_port: 110\n      server: \&quot;email.server.com\&quot;  # your mail server\n      username: \&quot;a@b.com\&quot; #\&quot;${POP3_USERNAME}\&quot;  # Will be replaced with environment variable\n      password: \&quot;password\&quot; #\&quot;${POP3_PASSWORD}\&quot;  # Will be replaced with environment variable\n      delete_after_download: false\n      security:\n        tls:\n          enabled: true\n          min_version: \&quot;1.2\&quot;\n          verify_cert: true\n        oauth2:\n          enabled: false\n          provider: \&quot;google\&quot;\n  retry:\n    max_attempts: 3\n    delay: 5\n  attachments:\n    allowed_types:\n      - \&quot;.jpg\&quot;\n      - \&quot;.jpeg\&quot;\n      - \&quot;.png\&quot;\n      - \&quot;.gif\&quot;\n      - \&quot;.pdf\&quot;\n      - \&quot;.xml\&quot;\n      - \&quot;.xlsx\&quot;\n      - \&quot;.xls\&quot;\n      - \&quot;.doc\&quot;\n      - \&quot;.docx\&quot;\n      - \&quot;.ppt\&quot;\n      - \&quot;.pptx\&quot;\n      - \&quot;.txt\&quot;\n      - \&quot;.csv\&quot;\n      - \&quot;.zip\&quot;\n      - \&quot;.rar\&quot;\n      - \&quot;.7z\&quot;\n      - \&quot;.rtf\&quot;\n    max_size: 104857600  # 100MB in bytes\n    storage_path: \&quot;/data/attachments\&quot;\n    naming_pattern: \&quot;${unixtime}_${filename}\&quot;\n    preserve_structure: true\n    scan_nested: true\n    sanitize_filenames: true\n    handle_duplicates: \&quot;increment\&quot;\n  tracking:\n    enabled: true\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/data/tracking\&quot;\n    retention_days: 30\n    tracking_format: \&quot;json\&quot;\n    track_downloaded: true\n  error_logging:\n    enabled: true\n    storage_type: \&quot;file\&quot;\n    storage_path: \&quot;/data/error_logs\&quot;\n    retention_days: 30\n    log_raw_message: false\n\nsecurity:\n  allowed_ips:\n    - \&quot;127.0.0.1\&quot;\n    - \&quot;::1\&quot;\n  api_keys:\n    - \&quot;test-key-1234567890abcdef\&quot;\n  cors:\n    enabled: true\n    allowed_origins:\n      - \&quot;http://localhost:3000\&quot;\n    allowed_methods:\n      - \&quot;GET\&quot;\n      - \&quot;POST\&quot;\n      - \&quot;PUT\&quot;\n      - \&quot;DELETE\&quot;\n    allowed_headers:\n      - \&quot;Authorization\&quot;\n      - \&quot;Content-Type\&quot;\n    expose_headers:\n      - \&quot;X-Request-ID\&quot;\n    max_age: 3600\n    allow_credentials: true\n  rate_limiting:\n    enabled: true\n    requests_per_second: 10\n    burst: 50\n\nlogging:\n  level: \&quot;debug\&quot;  # debug, info, warn, error\n  format: \&quot;json\&quot; # json, text\n  output: \&quot;stdout\&quot;  # stdout, file\n  file_path: \&quot;/var/log/email-extractor.log\&quot;\n  include_caller: true\n  redact_sensitive: true\n  rotation:\n    enabled: true\n    max_size: 100  # MB\n    max_age: 30    # days\n    max_backups: 5\n    compress: true\n\nmonitoring:\n  metrics_enabled: true\n  metrics_path: \&quot;/metrics\&quot;\n  health_check_path: \&quot;/health\&quot;\n  tracing:\n    enabled: true\n    exporter: \&quot;jaeger\&quot;\n    endpoint: \&quot;http://jaeger:14268/api/traces\&quot;\n    sample_rate: 0.1\n  profiling:\n    enabled: true\n    path: \&quot;/debug/pprof\&quot;\n  alerts:\n    enabled: true\n    endpoints:\n      - type: \&quot;email\&quot;\n        address: \&quot;alerts@example.com\&quot;\n    thresholds:\n      error_rate: 0.01\n      response_time_ms: 1000\n      disk_usage_percent: 90\n\nscheduling:\n  enabled: true\n  frequency_every: \&quot;minute\&quot;\n  frequency_amount: 3\n  start_now: true\n  start_at: \&quot;2024-03-15T00:00:00Z\&quot;\n  stop_at: \&quot;2025-12-31T23:59:59Z\&quot;\n\n# ... rest of the configuration remains the same ... \n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/types/config.go\n```go:internal/types/config.go\npackage types\n\n// Config represents the application configuration\ntype Config struct {\n\t// Meta information for the configuration\n\tMeta struct {\n\t\tID          string `yaml:\&quot;id\&quot;`\n\t\tName        string `yaml:\&quot;name\&quot;`\n\t\tDescription string `yaml:\&quot;description,omitempty\&quot;`\n\t\tEnabled     bool   `yaml:\&quot;enabled\&quot;`\n\t\tTemplate    string `yaml:\&quot;template,omitempty\&quot;` // Name of the template to use\n\t} `yaml:\&quot;meta\&quot;`\n\n\tServer struct {\n\t\tPort         int    `yaml:\&quot;port\&quot;`\n\t\tHost         string `yaml:\&quot;host\&quot;`\n\t\tReadTimeout  int    `yaml:\&quot;read_timeout\&quot;`\n\t\tWriteTimeout int    `yaml:\&quot;write_timeout\&quot;`\n\t\tIdleTimeout  int    `yaml:\&quot;idle_timeout\&quot;`\n\t} `yaml:\&quot;server\&quot;`\n\n\tEmail struct {\n\t\tDefaultTimeout int `yaml:\&quot;default_timeout\&quot;`\n\t\tRateLimit      int `yaml:\&quot;rate_limit\&quot;`\n\t\tMaxConcurrent  int `yaml:\&quot;max_concurrent\&quot;`\n\t\tProtocols      struct {\n\t\t\tIMAP struct {\n\t\t\t\tEnabled             bool     `yaml:\&quot;enabled\&quot;`\n\t\t\t\tDefaultPort         int      `yaml:\&quot;default_port\&quot;`\n\t\t\t\tInsecurePort        int      `yaml:\&quot;insecure_port\&quot;`\n\t\t\t\tIdleTimeout         int      `yaml:\&quot;idle_timeout\&quot;`\n\t\t\t\tBatchSize           int      `yaml:\&quot;batch_size\&quot;`\n\t\t\t\tServer              string   `yaml:\&quot;server\&quot;`\n\t\t\t\tUsername            string   `yaml:\&quot;username\&quot;`\n\t\t\t\tPassword            string   `yaml:\&quot;password\&quot;`\n\t\t\t\tFolders             []string `yaml:\&quot;folders\&quot;`\n\t\t\t\tUseIdle             bool     `yaml:\&quot;use_idle\&quot;`\n\t\t\t\tDeleteAfterDownload bool     `yaml:\&quot;delete_after_download\&quot;`\n\t\t\t\tSecurity            struct {\n\t\t\t\t\tTLS struct {\n\t\t\t\t\t\tEnabled    bool   `yaml:\&quot;enabled\&quot;`\n\t\t\t\t\t\tMinVersion string `yaml:\&quot;min_version\&quot;`\n\t\t\t\t\t\tVerifyCert bool   `yaml:\&quot;verify_cert\&quot;`\n\t\t\t\t\t\tCertFile   string `yaml:\&quot;cert_file\&quot;`\n\t\t\t\t\t\tKeyFile    string `yaml:\&quot;key_file\&quot;`\n\t\t\t\t\t} `yaml:\&quot;tls\&quot;`\n\t\t\t\t\tOAuth2 struct {\n\t\t\t\t\t\tEnabled      bool   `yaml:\&quot;enabled\&quot;`\n\t\t\t\t\t\tProvider     string `yaml:\&quot;provider\&quot;`\n\t\t\t\t\t\tClientID     string `yaml:\&quot;client_id\&quot;`\n\t\t\t\t\t\tClientSecret string `yaml:\&quot;client_secret\&quot;`\n\t\t\t\t\t} `yaml:\&quot;oauth2\&quot;`\n\t\t\t\t} `yaml:\&quot;security\&quot;`\n\t\t\t} `yaml:\&quot;imap\&quot;`\n\t\t\tPOP3 struct {\n\t\t\t\tEnabled             bool   `yaml:\&quot;enabled\&quot;`\n\t\t\t\tDefaultPort         int    `yaml:\&quot;default_port\&quot;`\n\t\t\t\tInsecurePort        int    `yaml:\&quot;insecure_port\&quot;`\n\t\t\t\tDeleteAfterDownload bool   `yaml:\&quot;delete_after_download\&quot;`\n\t\t\t\tServer              string `yaml:\&quot;server\&quot;`\n\t\t\t\tUsername            string `yaml:\&quot;username\&quot;`\n\t\t\t\tPassword            string `yaml:\&quot;password\&quot;`\n\t\t\t\tSecurity            struct {\n\t\t\t\t\tTLS struct {\n\t\t\t\t\t\tEnabled    bool   `yaml:\&quot;enabled\&quot;`\n\t\t\t\t\t\tMinVersion string `yaml:\&quot;min_version\&quot;`\n\t\t\t\t\t\tVerifyCert bool   `yaml:\&quot;verify_cert\&quot;`\n\t\t\t\t\t\tCertFile   string `yaml:\&quot;cert_file\&quot;`\n\t\t\t\t\t\tKeyFile    string `yaml:\&quot;key_file\&quot;`\n\t\t\t\t\t} `yaml:\&quot;tls\&quot;`\n\t\t\t\t\tOAuth2 struct {\n\t\t\t\t\t\tEnabled      bool   `yaml:\&quot;enabled\&quot;`\n\t\t\t\t\t\tProvider     string `yaml:\&quot;provider\&quot;`\n\t\t\t\t\t\tClientID     string `yaml:\&quot;client_id\&quot;`\n\t\t\t\t\t\tClientSecret string `yaml:\&quot;client_secret\&quot;`\n\t\t\t\t\t} `yaml:\&quot;oauth2\&quot;`\n\t\t\t\t} `yaml:\&quot;security\&quot;`\n\t\t\t} `yaml:\&quot;pop3\&quot;`\n\t\t} `yaml:\&quot;protocols\&quot;`\n\t\tRetry struct {\n\t\t\tMaxAttempts int `yaml:\&quot;max_attempts\&quot;`\n\t\t\tDelay       int `yaml:\&quot;delay\&quot;`\n\t\t} `yaml:\&quot;retry\&quot;`\n\t\tAttachments struct {\n\t\t\tAllowedTypes      []string `yaml:\&quot;allowed_types\&quot;`\n\t\t\tMaxSize           int64    `yaml:\&quot;max_size\&quot;`\n\t\t\tStoragePath       string   `yaml:\&quot;storage_path\&quot;`\n\t\t\tNamingPattern     string   `yaml:\&quot;naming_pattern\&quot;`\n\t\t\tPreserveStructure bool     `yaml:\&quot;preserve_structure\&quot;`\n\t\t\tSanitizeFilenames bool     `yaml:\&quot;sanitize_filenames\&quot;`\n\t\t\tHandleDuplicates  string   `yaml:\&quot;handle_duplicates\&quot;`\n\t\t} `yaml:\&quot;attachments\&quot;`\n\t\tTracking struct {\n\t\t\tEnabled         bool   `yaml:\&quot;enabled\&quot;`\n\t\t\tStorageType     string `yaml:\&quot;storage_type\&quot;`     // \&quot;file\&quot; or \&quot;database\&quot;\n\t\t\tStoragePath     string `yaml:\&quot;storage_path\&quot;`     // Path for file-based tracking\n\t\t\tRetentionDays   int    `yaml:\&quot;retention_days\&quot;`   // How long to keep tracking records\n\t\t\tTrackingFormat  string `yaml:\&quot;tracking_format\&quot;`  // \&quot;json\&quot; or \&quot;csv\&quot;\n\t\t\tTrackDownloaded bool   `yaml:\&quot;track_downloaded\&quot;` // Whether to track and skip already downloaded emails\n\t\t} `yaml:\&quot;tracking\&quot;`\n\t\tErrorLogging struct {\n\t\t\tEnabled       bool   `yaml:\&quot;enabled\&quot;`         // Whether error logging is enabled\n\t\t\tStorageType   string `yaml:\&quot;storage_type\&quot;`    // \&quot;file\&quot; or \&quot;database\&quot;\n\t\t\tStoragePath   string `yaml:\&quot;storage_path\&quot;`    // Path for file-based error logs\n\t\t\tRetentionDays int    `yaml:\&quot;retention_days\&quot;`  // How long to keep error logs\n\t\t\tLogRawMessage bool   `yaml:\&quot;log_raw_message\&quot;` // Whether to include raw message content in logs\n\t\t} `yaml:\&quot;error_logging\&quot;`\n\t} `yaml:\&quot;email\&quot;`\n\n\tSecurity struct {\n\t\tAllowedIPs []string `yaml:\&quot;allowed_ips\&quot;`\n\t\tAPIKeys    []string `yaml:\&quot;api_keys\&quot;`\n\t\tCORS       struct {\n\t\t\tEnabled          bool     `yaml:\&quot;enabled\&quot;`\n\t\t\tAllowedOrigins   []string `yaml:\&quot;allowed_origins\&quot;`\n\t\t\tAllowedMethods   []string `yaml:\&quot;allowed_methods\&quot;`\n\t\t\tAllowedHeaders   []string `yaml:\&quot;allowed_headers\&quot;`\n\t\t\tExposeHeaders    []string `yaml:\&quot;expose_headers\&quot;`\n\t\t\tMaxAge           int      `yaml:\&quot;max_age\&quot;`\n\t\t\tAllowCredentials bool     `yaml:\&quot;allow_credentials\&quot;`\n\t\t} `yaml:\&quot;cors\&quot;`\n\t\tRateLimiting struct {\n\t\t\tEnabled           bool `yaml:\&quot;enabled\&quot;`\n\t\t\tRequestsPerSecond int  `yaml:\&quot;requests_per_second\&quot;`\n\t\t\tBurst             int  `yaml:\&quot;burst\&quot;`\n\t\t} `yaml:\&quot;rate_limiting\&quot;`\n\t} `yaml:\&quot;security\&quot;`\n\n\tLogging struct {\n\t\tLevel           string `yaml:\&quot;level\&quot;`\n\t\tFormat          string `yaml:\&quot;format\&quot;`\n\t\tOutput          string `yaml:\&quot;output\&quot;`\n\t\tFilePath        string `yaml:\&quot;file_path\&quot;`\n\t\tIncludeCaller   bool   `yaml:\&quot;include_caller\&quot;`\n\t\tRedactSensitive bool   `yaml:\&quot;redact_sensitive\&quot;`\n\t\tRotation        struct {\n\t\t\tEnabled    bool `yaml:\&quot;enabled\&quot;`\n\t\t\tMaxSize    int  `yaml:\&quot;max_size\&quot;`\n\t\t\tMaxAge     int  `yaml:\&quot;max_age\&quot;`\n\t\t\tMaxBackups int  `yaml:\&quot;max_backups\&quot;`\n\t\t\tCompress   bool `yaml:\&quot;compress\&quot;`\n\t\t} `yaml:\&quot;rotation\&quot;`\n\t} `yaml:\&quot;logging\&quot;`\n\n\tMonitoring struct {\n\t\tMetricsEnabled  bool   `yaml:\&quot;metrics_enabled\&quot;`\n\t\tMetricsPath     string `yaml:\&quot;metrics_path\&quot;`\n\t\tHealthCheckPath string `yaml:\&quot;health_check_path\&quot;`\n\t\tTracing         struct {\n\t\t\tEnabled    bool    `yaml:\&quot;enabled\&quot;`\n\t\t\tExporter   string  `yaml:\&quot;exporter\&quot;`\n\t\t\tEndpoint   string  `yaml:\&quot;endpoint\&quot;`\n\t\t\tSampleRate float64 `yaml:\&quot;sample_rate\&quot;`\n\t\t} `yaml:\&quot;tracing\&quot;`\n\t\tProfiling struct {\n\t\t\tEnabled bool   `yaml:\&quot;enabled\&quot;`\n\t\t\tPath    string `yaml:\&quot;path\&quot;`\n\t\t} `yaml:\&quot;profiling\&quot;`\n\t\tAlerts struct {\n\t\t\tEnabled   bool `yaml:\&quot;enabled\&quot;`\n\t\t\tEndpoints []struct {\n\t\t\t\tType    string `yaml:\&quot;type\&quot;`\n\t\t\t\tAddress string `yaml:\&quot;address\&quot;`\n\t\t\t} `yaml:\&quot;endpoints\&quot;`\n\t\t\tThresholds struct {\n\t\t\t\tErrorRate        float64 `yaml:\&quot;error_rate\&quot;`\n\t\t\t\tResponseTimeMs   int     `yaml:\&quot;response_time_ms\&quot;`\n\t\t\t\tDiskUsagePercent int     `yaml:\&quot;disk_usage_percent\&quot;`\n\t\t\t} `yaml:\&quot;thresholds\&quot;`\n\t\t} `yaml:\&quot;alerts\&quot;`\n\t} `yaml:\&quot;monitoring\&quot;`\n\n\tScheduling struct {\n\t\tEnabled         bool   `yaml:\&quot;enabled\&quot;`\n\t\tFrequencyEvery  string `yaml:\&quot;frequency_every\&quot;`\n\t\tFrequencyAmount int    `yaml:\&quot;frequency_amount\&quot;`\n\t\tStartNow        bool   `yaml:\&quot;start_now\&quot;`\n\t\tStartAt         string `yaml:\&quot;start_at\&quot;`\n\t\tStopAt          string `yaml:\&quot;stop_at\&quot;`\n\t} `yaml:\&quot;scheduling\&quot;`\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/validation/config.go\n```go:internal/validation/config.go\npackage validation\n\nimport (\n\t\&quot;fmt\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/altafino/email-extractor/internal/types\&quot;\n)\n\n// ValidateConfig performs validation on a single configuration\nfunc ValidateConfig(cfg *types.Config) error {\n\tif err :\u003d validateMeta(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;meta validation failed: %w\&quot;, err)\n\t}\n\n\tif err :\u003d validateServer(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;server validation failed: %w\&quot;, err)\n\t}\n\n\tif err :\u003d validateEmail(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;email validation failed: %w\&quot;, err)\n\t}\n\n\tif err :\u003d validateSecurity(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;security validation failed: %w\&quot;, err)\n\t}\n\n\tif err :\u003d validateLogging(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;logging validation failed: %w\&quot;, err)\n\t}\n\n\tif err :\u003d validateScheduling(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;scheduling validation failed: %w\&quot;, err)\n\t}\n\n\treturn nil\n}\n\nfunc validateMeta(cfg *types.Config) error {\n\tif cfg.Meta.ID \u003d\u003d \&quot;\&quot; {\n\t\treturn fmt.Errorf(\&quot;meta.id is required\&quot;)\n\t}\n\n\tif !isValidID(cfg.Meta.ID) {\n\t\treturn fmt.Errorf(\&quot;meta.id contains invalid characters (use only alphanumeric, dash, underscore)\&quot;)\n\t}\n\n\tif cfg.Meta.Name \u003d\u003d \&quot;\&quot; {\n\t\treturn fmt.Errorf(\&quot;meta.name is required\&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc validateServer(cfg *types.Config) error {\n\tif cfg.Server.Port \u003c\u003d 0 || cfg.Server.Port \u003e 65535 {\n\t\treturn fmt.Errorf(\&quot;server.port must be between 1 and 65535\&quot;)\n\t}\n\n\tif cfg.Server.ReadTimeout \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;server.read_timeout must be positive\&quot;)\n\t}\n\n\tif cfg.Server.WriteTimeout \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;server.write_timeout must be positive\&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc validateEmail(cfg *types.Config) error {\n\n\t// Validate protocols configuration\n\tif cfg.Email.Protocols.IMAP.Enabled \u003d\u003d false \u0026\u0026 cfg.Email.Protocols.POP3.Enabled \u003d\u003d false {\n\t\treturn fmt.Errorf(\&quot;email.protocols.imap.enabled and email.protocols.pop3.enabled cannot both be false\&quot;)\n\t}\n\n\t// Validate protocols configuration\n\tif cfg.Email.Protocols.IMAP.Enabled \u003d\u003d true \u0026\u0026 cfg.Email.Protocols.POP3.Enabled \u003d\u003d true {\n\t\treturn fmt.Errorf(\&quot;email.protocols.imap.enabled and email.protocols.pop3.enabled cannot both be true\&quot;)\n\t}\n\n\tif cfg.Email.DefaultTimeout \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.default_timeout must be positive\&quot;)\n\t}\n\n\tif cfg.Email.RateLimit \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.rate_limit must be positive\&quot;)\n\t}\n\n\tif cfg.Email.MaxConcurrent \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.max_concurrent must be positive\&quot;)\n\t}\n\n\t// Validate attachments configuration\n\tif err :\u003d validateAttachments(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;attachments validation failed: %w\&quot;, err)\n\t}\n\n\t// Validate tracking configuration\n\tif err :\u003d validateTracking(cfg); err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;tracking validation failed: %w\&quot;, err)\n\t}\n\n\treturn nil\n}\n\nfunc validateAttachments(cfg *types.Config) error {\n\tif len(cfg.Email.Attachments.AllowedTypes) \u003d\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.attachments.allowed_types must not be empty\&quot;)\n\t}\n\n\tfor _, ext :\u003d range cfg.Email.Attachments.AllowedTypes {\n\t\tif !strings.HasPrefix(ext, \&quot;.\&quot;) {\n\t\t\treturn fmt.Errorf(\&quot;email.attachments.allowed_types: extension %q must start with dot\&quot;, ext)\n\t\t}\n\t}\n\n\tif cfg.Email.Attachments.MaxSize \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.attachments.max_size must be positive\&quot;)\n\t}\n\n\tif cfg.Email.Attachments.StoragePath \u003d\u003d \&quot;\&quot; {\n\t\treturn fmt.Errorf(\&quot;email.attachments.storage_path is required\&quot;)\n\t}\n\n\tif !filepath.IsAbs(cfg.Email.Attachments.StoragePath) {\n\t\treturn fmt.Errorf(\&quot;email.attachments.storage_path must be absolute\&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc validateTracking(cfg *types.Config) error {\n\tif !cfg.Email.Tracking.Enabled {\n\t\treturn nil // Skip validation if tracking is disabled\n\t}\n\n\tswitch cfg.Email.Tracking.StorageType {\n\tcase \&quot;file\&quot;, \&quot;database\&quot;:\n\t\t// Valid storage types\n\tdefault:\n\t\treturn fmt.Errorf(\&quot;email.tracking.storage_type must be \u0027file\u0027 or \u0027database\u0027\&quot;)\n\t}\n\n\tif cfg.Email.Tracking.StorageType \u003d\u003d \&quot;file\&quot; {\n\t\tif cfg.Email.Tracking.StoragePath \u003d\u003d \&quot;\&quot; {\n\t\t\treturn fmt.Errorf(\&quot;email.tracking.storage_path is required when storage_type is \u0027file\u0027\&quot;)\n\t\t}\n\t\tif !filepath.IsAbs(cfg.Email.Tracking.StoragePath) {\n\t\t\treturn fmt.Errorf(\&quot;email.tracking.storage_path must be absolute\&quot;)\n\t\t}\n\t}\n\n\tif cfg.Email.Tracking.RetentionDays \u003c\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;email.tracking.retention_days must be positive\&quot;)\n\t}\n\n\tswitch cfg.Email.Tracking.TrackingFormat {\n\tcase \&quot;json\&quot;, \&quot;csv\&quot;:\n\t\t// Valid formats\n\tdefault:\n\t\treturn fmt.Errorf(\&quot;email.tracking.tracking_format must be \u0027json\u0027 or \u0027csv\u0027\&quot;)\n\t}\n\n\t// No validation needed for track_downloaded as it\u0027s a boolean\n\n\treturn nil\n}\n\nfunc validateSecurity(cfg *types.Config) error {\n\tif len(cfg.Security.APIKeys) \u003d\u003d 0 {\n\t\treturn fmt.Errorf(\&quot;security.api_keys must not be empty\&quot;)\n\t}\n\n\tfor _, key :\u003d range cfg.Security.APIKeys {\n\t\tif len(key) \u003c 16 {\n\t\t\treturn fmt.Errorf(\&quot;security.api_keys: key length must be at least 16 characters\&quot;)\n\t\t}\n\t}\n\n\tif cfg.Security.CORS.Enabled {\n\t\tif len(cfg.Security.CORS.AllowedOrigins) \u003d\u003d 0 {\n\t\t\treturn fmt.Errorf(\&quot;security.cors.allowed_origins must not be empty when CORS is enabled\&quot;)\n\t\t}\n\t\tif len(cfg.Security.CORS.AllowedMethods) \u003d\u003d 0 {\n\t\t\treturn fmt.Errorf(\&quot;security.cors.allowed_methods must not be empty when CORS is enabled\&quot;)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc validateLogging(cfg *types.Config) error {\n\tvalidLevels :\u003d map[string]bool{\n\t\t\&quot;debug\&quot;: true,\n\t\t\&quot;info\&quot;:  true,\n\t\t\&quot;warn\&quot;:  true,\n\t\t\&quot;error\&quot;: true,\n\t}\n\n\tif !validLevels[cfg.Logging.Level] {\n\t\treturn fmt.Errorf(\&quot;logging.level must be one of: debug, info, warn, error\&quot;)\n\t}\n\n\tvalidFormats :\u003d map[string]bool{\n\t\t\&quot;text\&quot;: true,\n\t\t\&quot;json\&quot;: true,\n\t}\n\n\tif !validFormats[cfg.Logging.Format] {\n\t\treturn fmt.Errorf(\&quot;logging.format must be one of: text, json\&quot;)\n\t}\n\n\tvalidOutputs :\u003d map[string]bool{\n\t\t\&quot;stdout\&quot;: true,\n\t\t\&quot;file\&quot;:   true,\n\t}\n\n\tif !validOutputs[cfg.Logging.Output] {\n\t\treturn fmt.Errorf(\&quot;logging.output must be one of: stdout, file\&quot;)\n\t}\n\n\tif cfg.Logging.Output \u003d\u003d \&quot;file\&quot; \u0026\u0026 cfg.Logging.FilePath \u003d\u003d \&quot;\&quot; {\n\t\treturn fmt.Errorf(\&quot;logging.file_path is required when output is \u0027file\u0027\&quot;)\n\t}\n\n\treturn nil\n}\n\nfunc validateScheduling(cfg *types.Config) error {\n\tif !cfg.Scheduling.Enabled {\n\t\treturn nil // Skip validation if scheduling is disabled\n\t}\n\n\t// Validate frequency_every\n\tvalidFrequencies :\u003d map[string]bool{\n\t\t\&quot;minute\&quot;: true,\n\t\t\&quot;hour\&quot;:   true,\n\t\t\&quot;day\&quot;:    true,\n\t\t\&quot;week\&quot;:   true,\n\t\t\&quot;month\&quot;:  true,\n\t}\n\n\tif !validFrequencies[cfg.Scheduling.FrequencyEvery] {\n\t\treturn fmt.Errorf(\&quot;scheduling.frequency_every must be one of: minute, hour, day, week, month\&quot;)\n\t}\n\n\t// Validate frequency_amount\n\tif cfg.Scheduling.FrequencyAmount \u003c 1 {\n\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must be greater than 0\&quot;)\n\t}\n\n\t// Validate start and stop times if provided\n\tif !cfg.Scheduling.StartNow {\n\t\tif cfg.Scheduling.StartAt \u003d\u003d \&quot;\&quot; {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.start_at is required when start_now is false\&quot;)\n\t\t}\n\t\tif _, err :\u003d time.Parse(time.RFC3339, cfg.Scheduling.StartAt); err !\u003d nil {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.start_at must be in RFC3339 format (e.g., 2006-01-02T15:04:05Z)\&quot;)\n\t\t}\n\t}\n\n\tif cfg.Scheduling.StopAt !\u003d \&quot;\&quot; {\n\t\tstopAt, err :\u003d time.Parse(time.RFC3339, cfg.Scheduling.StopAt)\n\t\tif err !\u003d nil {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.stop_at must be in RFC3339 format (e.g., 2006-01-02T15:04:05Z)\&quot;)\n\t\t}\n\n\t\t// If start_at is provided, validate stop_at is after start_at\n\t\tif cfg.Scheduling.StartAt !\u003d \&quot;\&quot; {\n\t\t\tstartAt, _ :\u003d time.Parse(time.RFC3339, cfg.Scheduling.StartAt)\n\t\t\tif stopAt.Before(startAt) {\n\t\t\t\treturn fmt.Errorf(\&quot;scheduling.stop_at must be after start_at\&quot;)\n\t\t\t}\n\t\t}\n\n\t\t// If start_now is true, validate stop_at is in the future\n\t\tif cfg.Scheduling.StartNow {\n\t\t\tif stopAt.Before(time.Now().UTC()) {\n\t\t\t\treturn fmt.Errorf(\&quot;scheduling.stop_at must be in the future when start_now is true\&quot;)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Additional frequency-specific validations\n\tswitch cfg.Scheduling.FrequencyEvery {\n\tcase \&quot;minute\&quot;:\n\t\tif cfg.Scheduling.FrequencyAmount \u003e 60 {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must not exceed 60 for minute frequency\&quot;)\n\t\t}\n\tcase \&quot;hour\&quot;:\n\t\tif cfg.Scheduling.FrequencyAmount \u003e 24 {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must not exceed 24 for hour frequency\&quot;)\n\t\t}\n\tcase \&quot;day\&quot;:\n\t\tif cfg.Scheduling.FrequencyAmount \u003e 31 {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must not exceed 31 for day frequency\&quot;)\n\t\t}\n\tcase \&quot;week\&quot;:\n\t\tif cfg.Scheduling.FrequencyAmount \u003e 52 {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must not exceed 52 for week frequency\&quot;)\n\t\t}\n\tcase \&quot;month\&quot;:\n\t\tif cfg.Scheduling.FrequencyAmount \u003e 12 {\n\t\t\treturn fmt.Errorf(\&quot;scheduling.frequency_amount must not exceed 12 for month frequency\&quot;)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc isValidID(id string) bool {\n\tfor _, r :\u003d range id {\n\t\tif !isValidIDChar(r) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc isValidIDChar(r rune) bool {\n\treturn (r \u003e\u003d \u0027a\u0027 \u0026\u0026 r \u003c\u003d \u0027z\u0027) ||\n\t\t(r \u003e\u003d \u0027A\u0027 \u0026\u0026 r \u003c\u003d \u0027Z\u0027) ||\n\t\t(r \u003e\u003d \u00270\u0027 \u0026\u0026 r \u003c\u003d \u00279\u0027) ||\n\t\tr \u003d\u003d \u0027-\u0027 ||\n\t\tr \u003d\u003d \u0027_\u0027\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nadd StorageConfig to Attachment Part in Config\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you add the StorageConfig to the Attachments part of the Config struct in the `internal/types/config.go` file.\n\nHere\u0027s the necessary change:\n\n```go:internal/types/config.go\n// ... existing code ...\n\n\t\tAttachments struct {\n\t\t\tAllowedTypes      []string `yaml:\&quot;allowed_types\&quot;`\n\t\t\tMaxSize           int64    `yaml:\&quot;max_size\&quot;`\n\t\t\tStoragePath       string   `yaml:\&quot;storage_path\&quot;`\n\t\t\tNamingPattern     string   `yaml:\&quot;naming_pattern\&quot;`\n\t\t\tPreserveStructure bool     `yaml:\&quot;preserve_structure\&quot;`\n\t\t\tSanitizeFilenames bool     `yaml:\&quot;sanitize_filenames\&quot;`\n\t\t\tHandleDuplicates  string   `yaml:\&quot;handle_duplicates\&quot;`\n\t\t\tStorage          StorageConfig `yaml:\&quot;storage\&quot;` // Add this new field\n\t\t} `yaml:\&quot;attachments\&quot;`\n\n// ... existing code ...\n\n// Add this new type definition somewhere in the file\ntype StorageConfig struct {\n\tType            string `yaml:\&quot;type\&quot;`            // \&quot;file\&quot; or \&quot;gdrive\&quot;\n\tCredentialsFile string `yaml:\&quot;credentials_file\&quot; yaml:\&quot;,omitempty\&quot;` // Path to Google Drive credentials JSON file\n\tParentFolderID  string `yaml:\&quot;parent_folder_id\&quot; yaml:\&quot;,omitempty\&quot;` // Google Drive folder ID where files will be stored\n}\n\n// ... rest of the file ...\n```\n\nThis change will:\n1. Add a new StorageConfig field to the Attachments struct\n2. Define the StorageConfig type with the necessary fields for both file system and Google Drive storage options\n3. Use yaml tags to properly map the configuration fields\n\nYou\u0027ll also need to update your configuration files to include this new structure if you want to specify storage settings. The default would typically be file-based storage if not specified.&quot;}]}" />
        <entry key="50917f1f-7bdc-4b9b-9af4-3ae54cbf19da" value="{&quot;id&quot;:&quot;50917f1f-7bdc-4b9b-9af4-3ae54cbf19da&quot;,&quot;name&quot;:&quot;Refactoring SaveAttachment Function for Multiple Storage Implementations&quot;,&quot;timestamp&quot;:1740829191634,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nThe SaveAttachment function stores content []byte according to config on file storage\nI want to make a implementation with an Interface, which allows to have different implementations of storage:\n- File (as the existing)\n- Google Drive\n- S3 compatible Bucket Storage\n\nRefactor and implement first the interface and the file storage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;There was an unknown error. Here is my cutoff response:\n&quot;}]}" />
        <entry key="bfb030a8-b778-4d37-afcc-8c28f90d966c" value="{&quot;id&quot;:&quot;bfb030a8-b778-4d37-afcc-8c28f90d966c&quot;,&quot;name&quot;:&quot;Refactoring SaveAttachment Function to Support Multiple Storage Implementations&quot;,&quot;timestamp&quot;:1740857738222,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nThe SaveAttachment function stores content []byte according to config on file storage\nI want to make a implementation with an Interface, which allows to have different implementations of storage:\n- File (as the existing)\n- Google Drive\n- S3 compatible Bucket Storage\n\nRefactor and implement first the interface and the file storage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you refactor the code to use an interface for storage implementations. Here\u0027s how we can modify the code:\n\n1. First, let\u0027s create the storage interface and necessary types:\n\n```go:internal/email/parser/storage.go\npackage parser\n\nimport (\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n```\n\n2. Now let\u0027s modify the existing SaveAttachment function to use the new interface structure:\n\n```go:internal/email/parser/attachments.go\n// ... existing imports and code ...\n\n// FileStorage implementation of Save\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n```\n\nThe main changes are:\n\n1. Created a new interface `AttachmentStorage` that defines the contract for different storage implementations\n2. Moved the existing file storage implementation into a `FileStorage` struct that implements the interface\n3. Split the large `Save` method into smaller, more manageable helper methods\n4. Added a constructor function `NewFileStorage` for creating new storage instances\n\nNow you can use it like this:\n\n```go\n// Create a storage instance\nstorage :\u003d NewFileStorage(logger)\n\n// Use the storage\npath, err :\u003d storage.Save(filename, content, config)\nif err !\u003d nil {\n    // Handle error\n}\n```\n\nThis refactoring makes it easy to add new storage implementations (like Google Drive or S3) by creating new structs that implement the `AttachmentStorage` interface. Each implementation can handle its own specific logic while maintaining the same interface contract.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nnow lets implement storage for cloud providers, using https://github.com/rclone/rclone\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you create a new storage implementation using rclone, which will allow us to support multiple cloud providers (like S3, Google Drive, etc.) through a single interface.\n\nFirst, let\u0027s create a new file for the rclone storage implementation:\n\n```go:internal/email/attachment/rclone_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/rclone/rclone/fs\&quot;\n\t\&quot;github.com/rclone/rclone/fs/config\&quot;\n\t\&quot;github.com/rclone/rclone/fs/operations\&quot;\n)\n\n// RcloneStorage implements AttachmentStorage for cloud storage using rclone\ntype RcloneStorage struct {\n\tlogger     *slog.Logger\n\tfsInstance fs.Fs\n}\n\n// NewRcloneStorage creates a new RcloneStorage instance\nfunc NewRcloneStorage(logger *slog.Logger, provider, remote string) (AttachmentStorage, error) {\n\t// Initialize rclone fs\n\tfsInstance, err :\u003d fs.NewFs(context.Background(), remote)\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to initialize rclone fs: %w\&quot;, err)\n\t}\n\n\treturn \u0026RcloneStorage{\n\t\tlogger:     logger,\n\t\tfsInstance: fsInstance,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for cloud storage\nfunc (rs *RcloneStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tstoragePath :\u003d config.StoragePath\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\t\n\tif hasVars {\n\t\tstoragePath \u003d rs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final path\n\tfinalPath :\u003d rs.getFinalPath(storagePath, filename, hasVars, config.PreserveStructure, now)\n\n\trs.logger.Debug(\&quot;saving to cloud storage\&quot;,\n\t\t\&quot;final_path\&quot;, finalPath,\n\t\t\&quot;size\&quot;, len(content))\n\n\t// Create a reader from the content\n\tcontentReader :\u003d strings.NewReader(string(content))\n\n\t// Use rclone operations to save the file\n\tobj, err :\u003d operations.Rcat(context.Background(), rs.fsInstance, finalPath, contentReader, time.Now(), nil)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\t// Return the remote path\n\treturn obj.Remote(), nil\n}\n\n// Helper methods\n\nfunc (rs *RcloneStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (rs *RcloneStorage) getFinalPath(storagePath, filename string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir, filename)\n\t}\n\treturn filepath.Join(storagePath, filename)\n}\n```\n\nNow let\u0027s update the main storage interface file to include a configuration for creating storage instances:\n\n```go:internal/email/attachment/storage.go\n// ... existing imports ...\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeRclone StorageType \u003d \&quot;rclone\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType         StorageType\n\tRcloneRemote string // Remote name configured in rclone\n\tRcloneConfig string // Optional path to rclone config file\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeRclone:\n\t\treturn NewRcloneStorage(logger, config.RcloneRemote)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n```\n\nExample usage:\n\n```go\n// Create a file storage\nfileStorage, err :\u003d NewStorage(StorageConfig{\n    Type: StorageTypeFile,\n}, logger)\n\n// Create an S3 storage using rclone\ns3Storage, err :\u003d NewStorage(StorageConfig{\n    Type:         StorageTypeRclone,\n    RcloneRemote: \&quot;s3:mybucket/path\&quot;,\n}, logger)\n\n// Create a Google Drive storage using rclone\ndriveStorage, err :\u003d NewStorage(StorageConfig{\n    Type:         StorageTypeRclone,\n    RcloneRemote: \&quot;gdrive:backup/attachments\&quot;,\n}, logger)\n```\n\nTo use this implementation, you\u0027ll need to:\n\n1. Add the rclone dependency to your go.mod:\n```bash\ngo get github.com/rclone/rclone\n```\n\n2. Configure rclone for your cloud provider. You can do this using the rclone command-line tool:\n```bash\nrclone config\n```\n\n3. The rclone configuration will support many cloud providers including:\n- Amazon S3\n- Google Drive\n- Microsoft OneDrive\n- Dropbox\n- And many others\n\nBenefits of using rclone:\n1. Supports many cloud providers through a single interface\n2. Handles authentication and retry logic\n3. Provides efficient transfer mechanisms\n4. Maintains compatibility with provider-specific features\n\nThe implementation handles:\n1. File naming and path construction\n2. Size validation\n3. Directory structure preservation\n4. Variable substitution in paths\n5. Proper error handling\n\nRemember to properly configure rclone for your chosen cloud provider before using the RcloneStorage implementation.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/filestorage.go\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\nimport (\n\t\&quot;fmt\&quot;\n\t\&quot;net/http\&quot;\n\t\&quot;os\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n)\n\n// FileStorage implementation of Save to store attachments on disk\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nlets restart on it, but implement only Google Drive\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you implement a Google Drive storage solution. We\u0027ll create a new implementation using the official Google Drive API instead of rclone for better control and direct integration.\n\nFirst, let\u0027s create a new file for the Google Drive storage implementation:\n\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger     *slog.Logger\n\tservice    *drive.Service\n\tparentID   string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;, \n\t\t\tpart, currentParentID)\n\t\t\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n```\n\nNow let\u0027s update the storage interface file to include the Google Drive storage type:\n\n```go:internal/email/attachment/storage.go\n// ... existing imports ...\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType              StorageType\n\tCredentialsFile   string // Path to Google Drive credentials JSON file\n\tParentFolderID    string // Google Drive folder ID where files will be stored\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n```\n\nTo use this implementation, you\u0027ll need to:\n\n1. Add the Google Drive API dependency to your go.mod:\n```bash\ngo get google.golang.org/api/drive/v3\n```\n\n2. Set up Google Cloud Project and obtain credentials:\n   - Go to Google Cloud Console\n   - Create a new project or select an existing one\n   - Enable the Google Drive API\n   - Create credentials (OAuth 2.0 Client ID or Service Account)\n   - Download the credentials JSON file\n\nExample usage:\n\n```go\n// Create storage configuration\nconfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Create storage instance\nstorage, err :\u003d NewStorage(context.Background(), config, logger)\nif err !\u003d nil {\n    log.Fatal(err)\n}\n\n// Use the storage\nattachmentConfig :\u003d AttachmentConfig{\n    StoragePath:       \&quot;attachments/${YYYY}/${MM}\&quot;,\n    MaxSize:           10 * 1024 * 1024, // 10MB\n    SanitizeFilenames: true,\n    PreserveStructure: true,\n}\n\npath, err :\u003d storage.Save(\&quot;document.pdf\&quot;, content, attachmentConfig)\nif err !\u003d nil {\n    log.Fatal(err)\n}\n```\n\nThis implementation:\n1. Uses the official Google Drive API\n2. Supports folder hierarchy creation\n3. Handles file uploads with proper MIME types\n4. Maintains the same interface as the file storage implementation\n5. Supports variable substitution in paths\n6. Includes proper error handling and logging\n\nRemember to properly configure Google Drive API access and keep your credentials secure. The returned path will be the Google Drive file ID, which can be used to reference the file later.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger     *slog.Logger\n\tservice    *drive.Service\n\tparentID   string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;, \n\t\t\tpart, currentParentID)\n\t\t\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nwhat we need to change in attachments to use this?\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;We need to modify the `SaveAttachment` function in `attachments.go` to use the new storage configuration and factory method. Here\u0027s the change needed:\n\n```go:internal/email/attachment/attachments.go\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n    // Create storage instance based on configuration\n    storage, err :\u003d NewStorage(ctx, storageConfig, logger)\n    if err !\u003d nil {\n        return \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n    }\n\n    // Use the storage implementation to save the attachment\n    return storage.Save(filename, content, config)\n}\n```\n\nAnd you\u0027ll need to update any code that calls `SaveAttachment` to include the storage configuration. For example:\n\n```go\n// For file storage:\nstorageConfig :\u003d StorageConfig{\n    Type: StorageTypeFile,\n}\n\n// For Google Drive storage:\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;/path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Call SaveAttachment with the new parameters\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```\n\nThe main changes are:\n1. Added context.Context parameter for Google Drive API\n2. Added StorageConfig parameter to specify the storage type and its configuration\n3. Using the new factory method `NewStorage` instead of directly creating `FileStorage`\n4. Improved error handling to include storage initialization errors\n\nThis change makes the storage backend configurable while maintaining the existing attachment processing logic.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// StorageConfig holds configuration for storage\ntype StorageConfig struct {\n\tType            string\n\tCredentialsFile string\n\tParentFolderID  string\n}\n\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\t// Create storage instance based on configuration\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\n\t// Use the storage implementation to save the attachment\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nwe have now conflicting StorageConfig\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;Yes, we have two different `StorageConfig` definitions. Let\u0027s consolidate them into a single definition in `storage.go` since that\u0027s where we define our storage interfaces and types:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen we need to remove the `StorageConfig` definition from `attachments.go`. The example usage would now look like:\n\n```go\n// Create storage configuration for file storage\nstorageConfig :\u003d StorageConfig{\n    Type: StorageTypeFile,\n}\n\n// Or for Google Drive storage\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;/path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Use in SaveAttachment\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```\n\nThe changes:\n1. Moved all storage-related types to `storage.go`\n2. Removed duplicate `StorageConfig` from `attachments.go`\n3. Added proper type for storage type using `StorageType` enum\n4. Consolidated all storage-related code in one place\n\nThis makes the code more organized and prevents type conflicts.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\t// Create storage instance based on configuration\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\n\t// Use the storage implementation to save the attachment\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nplease fix:\n\ninternal/email/attachment/storage.go:8:6: AttachmentStorage redeclared in this block\n        internal/email/attachment/filestorage.go:30:6: other declaration of AttachmentStorage\ninternal/email/attachment/storage.go:14:6: NewFileStorage redeclared in this block\n        internal/email/attachment/filestorage.go:53:6: other declaration of NewFileStorage\ninternal/email/attachment/storage.go:19:6: FileStorage redeclared in this block\n        internal/email/attachment/filestorage.go:48:6: other declaration of FileStorage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;We need to consolidate the declarations since we have duplicate definitions across files. Let\u0027s update `storage.go` to contain all the interface and type definitions while removing them from other files:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) *FileStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen we should remove these declarations from `filestorage.go` and keep only the implementation:\n\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\n// Keep only the Save method and helper methods\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n    // ... existing implementation ...\n}\n\n// ... helper methods ...\n```\n\nAnd in `attachments.go`, update the `SaveAttachment` function to use the proper type:\n\n```go:internal/email/attachment/attachments.go\n// Update the existing StorageConfig reference to use StorageType\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n    // Create storage instance based on configuration\n    storage, err :\u003d NewStorage(ctx, storageConfig, logger)\n    if err !\u003d nil {\n        return \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n    }\n\n    // Use the storage implementation to save the attachment\n    return storage.Save(filename, content, config)\n}\n```\n\nThis reorganization:\n1. Consolidates all interface and type definitions in `storage.go`\n2. Removes duplicate declarations from other files\n3. Keeps implementation details in their respective files\n4. Maintains proper type safety with the `StorageType` enum\n\nThe code should now compile without any redeclaration errors while maintaining the same functionality.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/filestorage.go\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\nimport (\n\t\&quot;fmt\&quot;\n\t\&quot;net/http\&quot;\n\t\&quot;os\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n)\n\n// FileStorage implementation of Save to store attachments on disk\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\ninternal/email/attachment/attachments.go:324:114: undefined: StorageConfig\ninternal/email/attachment/attachments.go:326:18: undefined: NewStorage\nfix\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;The error occurs because we haven\u0027t properly imported or defined the storage types. Let\u0027s fix this by adding the necessary type definitions and functions to `storage.go`:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen in `attachments.go`, add `context` to the imports if it\u0027s not already there:\n\n```go:internal/email/attachment/attachments.go\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;  // Make sure this is included\n\t// ... other imports ...\n)\n\n// The SaveAttachment function should now compile correctly\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\treturn storage.Save(filename, content, config)\n}\n```\n\nThe code should now compile successfully since:\n1. `StorageConfig` is properly defined in `storage.go`\n2. `NewStorage` function is available from `storage.go`\n3. All necessary types and functions are in the same package\n4. The required imports are in place\n\nYou can use it like this:\n\n```go\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeFile, // or StorageTypeGDrive\n    CredentialsFile: \&quot;path/to/credentials.json\&quot;, // only needed for GDrive\n    ParentFolderID:  \&quot;folder_id\&quot;,               // only needed for GDrive\n}\n\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nexplain the code\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;The request was cancelled. Here is my cutoff response:\n&quot;}]}" />
        <entry key="c2995eaa-ffe7-43b7-8a30-eaade14bd7a1" value="{&quot;id&quot;:&quot;c2995eaa-ffe7-43b7-8a30-eaade14bd7a1&quot;,&quot;name&quot;:&quot;Suggesting Improvements&quot;,&quot;timestamp&quot;:1740463359367,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nsuggest improvements\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;Here are some suggested improvements for your Go code:\n\n1. **Error Handling in Viper Bindings**:\n```go:cmd/server/main.go\n// ... existing code ...\nif err :\u003d viper.BindPFlag(\&quot;logging.level\&quot;, rootCmd.PersistentFlags().Lookup(\&quot;log-level\&quot;)); err !\u003d nil {\n    logger.Error(\&quot;failed to bind log-level flag\&quot;, \&quot;error\&quot;, err)\n}\n// Repeat similar error handling for other BindPFlag calls\n// ... existing code ...\n```\n\n2. **Config Loading Improvement**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc initConfig() {\n    // ... existing code ...\n    configs :\u003d config.GetEnabledConfigs()\n    if len(configs) \u003d\u003d 0 {\n        logger.Error(\&quot;no enabled configurations found\&quot;, \&quot;config_dir\&quot;, configDir)\n        os.Exit(1)\n    }\n    // ... existing code ...\n}\n// ... existing code ...\n```\n\n3. **Graceful Shutdown Improvements**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc run(cmd *cobra.Command, args []string) error {\n    // ... existing code ...\n    ctx, cancel :\u003d context.WithTimeout(context.Background(), 30*time.Second)\n    defer cancel()\n    \n    if err :\u003d app.Stop(ctx); err !\u003d nil {\n        logger.Error(\&quot;failed to stop application gracefully\&quot;, \&quot;error\&quot;, err)\n        return err\n    }\n    return nil\n}\n// ... existing code ...\n```\n\n4. **Documentation Comments**:\n```go:cmd/server/main.go\n// rootCmd represents the base command when called without any subcommands\nvar rootCmd \u003d \u0026cobra.Command{\n    // ... existing code ...\n}\n\n// initConfig reads in config file and ENV variables if set.\nfunc initConfig() {\n    // ... existing code ...\n}\n\n// run is the main execution function for the root command\nfunc run(cmd *cobra.Command, args []string) error {\n    // ... existing code ...\n}\n```\n\n5. **Configuration Validation**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc initConfig() {\n    // ... existing code ...\n    if configID !\u003d \&quot;\&quot; {\n        if cfg, err :\u003d config.GetConfig(configID); err \u003d\u003d nil {\n            if err :\u003d cfg.Validate(); err !\u003d nil {\n                logger.Error(\&quot;invalid configuration\&quot;, \&quot;config_id\&quot;, configID, \&quot;error\&quot;, err)\n                os.Exit(1)\n            }\n            // ... existing code ...\n// ... existing code ...\n```\n\nAdditional suggestions:\n- Add version flag (`--version`) using cobra\n- Implement structured logging consistently throughout\n- Add context.Context to application methods\n- Consider adding configuration reload capabilities (watch config files)\n- Add proper signal handling for SIGHUP (for config reload)\n- Implement health checks and readiness probes\n- Add more detailed command-line help text\n- Consider adding subcommands for various operations\n\nThese improvements would make your code more robust, maintainable, and production-ready. The changes focus on better error handling, documentation, graceful shutdown, and configuration management.&quot;}]}" />
      </map>
    </option>
  </component>
</project>