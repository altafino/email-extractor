<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChatHistoryState">
    <option name="serializedSessions">
      <map>
        <entry key="0ed78732-d0d8-49c7-b9b1-69b023d5a247" value="{&quot;id&quot;:&quot;0ed78732-d0d8-49c7-b9b1-69b023d5a247&quot;,&quot;name&quot;:&quot;Code Explanation Request&quot;,&quot;timestamp&quot;:1740857865214,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nexplain code\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;This code implements a POP3 (Post Office Protocol version 3) email client in Go. Here\u0027s a high-level breakdown of its main components and functionality:\n\n### Main Components\n\n1. **POP3Client Struct**\n```go\ntype POP3Client struct {\n    cfg    *types.Config\n    logger *slog.Logger\n}\n```\n- Basic client structure holding configuration and logging capabilities\n\n2. **MIME Type Mapping**\n- Comprehensive map (`mimeToExt`) of MIME types to file extensions\n- Used for proper file extension assignment when saving attachments\n\n### Key Functions\n\n1. **Connect Function**\n- Establishes connection to POP3 server\n- Handles TLS configuration\n- Performs authentication\n- Includes secure password logging (obfuscated)\n\n2. **DownloadEmails Function**\n- Main workflow for downloading emails\n- Features:\n  - Tracking of downloaded emails\n  - Error logging\n  - Attachment processing\n  - Email parsing\n  - Message deletion (optional)\n\n3. **Content Processing Functions**\n- `decodeContent`: Handles different email content encodings (base64, quoted-printable)\n- `extractAttachmentsMultipart`: Processes multipart email messages to extract attachments\n- `generateUniqueMessageID`: Creates unique identifiers for messages\n\n### Key Features\n\n1. **Security**\n- TLS support\n- Password obfuscation in logs\n- Certificate verification options\n\n2. **Robust Error Handling**\n- Comprehensive error logging\n- Graceful failure handling\n- Detailed error tracking\n\n3. **Attachment Processing**\n- MIME type detection\n- File name sanitization\n- Size limitations\n- Allowed file type filtering\n\n4. **Email Tracking**\n- Prevents duplicate downloads\n- Tracks successful downloads\n- Maintains download history\n\n5. **Configuration Options**\n- Configurable deletion after download\n- Flexible attachment storage options\n- Customizable security settings\n\nThis implementation provides a robust solution for downloading emails and attachments via POP3, with strong emphasis on error handling, security, and configurability.&quot;}]}" />
        <entry key="50917f1f-7bdc-4b9b-9af4-3ae54cbf19da" value="{&quot;id&quot;:&quot;50917f1f-7bdc-4b9b-9af4-3ae54cbf19da&quot;,&quot;name&quot;:&quot;Refactoring SaveAttachment Function for Multiple Storage Implementations&quot;,&quot;timestamp&quot;:1740829191634,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nThe SaveAttachment function stores content []byte according to config on file storage\nI want to make a implementation with an Interface, which allows to have different implementations of storage:\n- File (as the existing)\n- Google Drive\n- S3 compatible Bucket Storage\n\nRefactor and implement first the interface and the file storage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;There was an unknown error. Here is my cutoff response:\n&quot;}]}" />
        <entry key="bfb030a8-b778-4d37-afcc-8c28f90d966c" value="{&quot;id&quot;:&quot;bfb030a8-b778-4d37-afcc-8c28f90d966c&quot;,&quot;name&quot;:&quot;Refactoring SaveAttachment Function to Support Multiple Storage Implementations&quot;,&quot;timestamp&quot;:1740857738222,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nThe SaveAttachment function stores content []byte according to config on file storage\nI want to make a implementation with an Interface, which allows to have different implementations of storage:\n- File (as the existing)\n- Google Drive\n- S3 compatible Bucket Storage\n\nRefactor and implement first the interface and the file storage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you refactor the code to use an interface for storage implementations. Here\u0027s how we can modify the code:\n\n1. First, let\u0027s create the storage interface and necessary types:\n\n```go:internal/email/parser/storage.go\npackage parser\n\nimport (\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n```\n\n2. Now let\u0027s modify the existing SaveAttachment function to use the new interface structure:\n\n```go:internal/email/parser/attachments.go\n// ... existing imports and code ...\n\n// FileStorage implementation of Save\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n```\n\nThe main changes are:\n\n1. Created a new interface `AttachmentStorage` that defines the contract for different storage implementations\n2. Moved the existing file storage implementation into a `FileStorage` struct that implements the interface\n3. Split the large `Save` method into smaller, more manageable helper methods\n4. Added a constructor function `NewFileStorage` for creating new storage instances\n\nNow you can use it like this:\n\n```go\n// Create a storage instance\nstorage :\u003d NewFileStorage(logger)\n\n// Use the storage\npath, err :\u003d storage.Save(filename, content, config)\nif err !\u003d nil {\n    // Handle error\n}\n```\n\nThis refactoring makes it easy to add new storage implementations (like Google Drive or S3) by creating new structs that implement the `AttachmentStorage` interface. Each implementation can handle its own specific logic while maintaining the same interface contract.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nnow lets implement storage for cloud providers, using https://github.com/rclone/rclone\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you create a new storage implementation using rclone, which will allow us to support multiple cloud providers (like S3, Google Drive, etc.) through a single interface.\n\nFirst, let\u0027s create a new file for the rclone storage implementation:\n\n```go:internal/email/attachment/rclone_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/rclone/rclone/fs\&quot;\n\t\&quot;github.com/rclone/rclone/fs/config\&quot;\n\t\&quot;github.com/rclone/rclone/fs/operations\&quot;\n)\n\n// RcloneStorage implements AttachmentStorage for cloud storage using rclone\ntype RcloneStorage struct {\n\tlogger     *slog.Logger\n\tfsInstance fs.Fs\n}\n\n// NewRcloneStorage creates a new RcloneStorage instance\nfunc NewRcloneStorage(logger *slog.Logger, provider, remote string) (AttachmentStorage, error) {\n\t// Initialize rclone fs\n\tfsInstance, err :\u003d fs.NewFs(context.Background(), remote)\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to initialize rclone fs: %w\&quot;, err)\n\t}\n\n\treturn \u0026RcloneStorage{\n\t\tlogger:     logger,\n\t\tfsInstance: fsInstance,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for cloud storage\nfunc (rs *RcloneStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tstoragePath :\u003d config.StoragePath\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\t\n\tif hasVars {\n\t\tstoragePath \u003d rs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final path\n\tfinalPath :\u003d rs.getFinalPath(storagePath, filename, hasVars, config.PreserveStructure, now)\n\n\trs.logger.Debug(\&quot;saving to cloud storage\&quot;,\n\t\t\&quot;final_path\&quot;, finalPath,\n\t\t\&quot;size\&quot;, len(content))\n\n\t// Create a reader from the content\n\tcontentReader :\u003d strings.NewReader(string(content))\n\n\t// Use rclone operations to save the file\n\tobj, err :\u003d operations.Rcat(context.Background(), rs.fsInstance, finalPath, contentReader, time.Now(), nil)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\t// Return the remote path\n\treturn obj.Remote(), nil\n}\n\n// Helper methods\n\nfunc (rs *RcloneStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (rs *RcloneStorage) getFinalPath(storagePath, filename string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir, filename)\n\t}\n\treturn filepath.Join(storagePath, filename)\n}\n```\n\nNow let\u0027s update the main storage interface file to include a configuration for creating storage instances:\n\n```go:internal/email/attachment/storage.go\n// ... existing imports ...\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeRclone StorageType \u003d \&quot;rclone\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType         StorageType\n\tRcloneRemote string // Remote name configured in rclone\n\tRcloneConfig string // Optional path to rclone config file\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeRclone:\n\t\treturn NewRcloneStorage(logger, config.RcloneRemote)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n```\n\nExample usage:\n\n```go\n// Create a file storage\nfileStorage, err :\u003d NewStorage(StorageConfig{\n    Type: StorageTypeFile,\n}, logger)\n\n// Create an S3 storage using rclone\ns3Storage, err :\u003d NewStorage(StorageConfig{\n    Type:         StorageTypeRclone,\n    RcloneRemote: \&quot;s3:mybucket/path\&quot;,\n}, logger)\n\n// Create a Google Drive storage using rclone\ndriveStorage, err :\u003d NewStorage(StorageConfig{\n    Type:         StorageTypeRclone,\n    RcloneRemote: \&quot;gdrive:backup/attachments\&quot;,\n}, logger)\n```\n\nTo use this implementation, you\u0027ll need to:\n\n1. Add the rclone dependency to your go.mod:\n```bash\ngo get github.com/rclone/rclone\n```\n\n2. Configure rclone for your cloud provider. You can do this using the rclone command-line tool:\n```bash\nrclone config\n```\n\n3. The rclone configuration will support many cloud providers including:\n- Amazon S3\n- Google Drive\n- Microsoft OneDrive\n- Dropbox\n- And many others\n\nBenefits of using rclone:\n1. Supports many cloud providers through a single interface\n2. Handles authentication and retry logic\n3. Provides efficient transfer mechanisms\n4. Maintains compatibility with provider-specific features\n\nThe implementation handles:\n1. File naming and path construction\n2. Size validation\n3. Directory structure preservation\n4. Variable substitution in paths\n5. Proper error handling\n\nRemember to properly configure rclone for your chosen cloud provider before using the RcloneStorage implementation.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/filestorage.go\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\nimport (\n\t\&quot;fmt\&quot;\n\t\&quot;net/http\&quot;\n\t\&quot;os\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n)\n\n// FileStorage implementation of Save to store attachments on disk\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nlets restart on it, but implement only Google Drive\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;I\u0027ll help you implement a Google Drive storage solution. We\u0027ll create a new implementation using the official Google Drive API instead of rclone for better control and direct integration.\n\nFirst, let\u0027s create a new file for the Google Drive storage implementation:\n\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger     *slog.Logger\n\tservice    *drive.Service\n\tparentID   string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;, \n\t\t\tpart, currentParentID)\n\t\t\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n```\n\nNow let\u0027s update the storage interface file to include the Google Drive storage type:\n\n```go:internal/email/attachment/storage.go\n// ... existing imports ...\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType              StorageType\n\tCredentialsFile   string // Path to Google Drive credentials JSON file\n\tParentFolderID    string // Google Drive folder ID where files will be stored\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n```\n\nTo use this implementation, you\u0027ll need to:\n\n1. Add the Google Drive API dependency to your go.mod:\n```bash\ngo get google.golang.org/api/drive/v3\n```\n\n2. Set up Google Cloud Project and obtain credentials:\n   - Go to Google Cloud Console\n   - Create a new project or select an existing one\n   - Enable the Google Drive API\n   - Create credentials (OAuth 2.0 Client ID or Service Account)\n   - Download the credentials JSON file\n\nExample usage:\n\n```go\n// Create storage configuration\nconfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Create storage instance\nstorage, err :\u003d NewStorage(context.Background(), config, logger)\nif err !\u003d nil {\n    log.Fatal(err)\n}\n\n// Use the storage\nattachmentConfig :\u003d AttachmentConfig{\n    StoragePath:       \&quot;attachments/${YYYY}/${MM}\&quot;,\n    MaxSize:           10 * 1024 * 1024, // 10MB\n    SanitizeFilenames: true,\n    PreserveStructure: true,\n}\n\npath, err :\u003d storage.Save(\&quot;document.pdf\&quot;, content, attachmentConfig)\nif err !\u003d nil {\n    log.Fatal(err)\n}\n```\n\nThis implementation:\n1. Uses the official Google Drive API\n2. Supports folder hierarchy creation\n3. Handles file uploads with proper MIME types\n4. Maintains the same interface as the file storage implementation\n5. Supports variable substitution in paths\n6. Includes proper error handling and logging\n\nRemember to properly configure Google Drive API access and keep your credentials secure. The returned path will be the Google Drive file ID, which can be used to reference the file later.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content to a file with proper naming and permissions\nfunc SaveAttachment(filename string, content []byte, config AttachmentConfig, logger *slog.Logger) (string, error) {\n\tstorage :\u003d NewFileStorage(logger)\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger     *slog.Logger\n\tservice    *drive.Service\n\tparentID   string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;, \n\t\t\tpart, currentParentID)\n\t\t\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nwhat we need to change in attachments to use this?\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;We need to modify the `SaveAttachment` function in `attachments.go` to use the new storage configuration and factory method. Here\u0027s the change needed:\n\n```go:internal/email/attachment/attachments.go\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n    // Create storage instance based on configuration\n    storage, err :\u003d NewStorage(ctx, storageConfig, logger)\n    if err !\u003d nil {\n        return \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n    }\n\n    // Use the storage implementation to save the attachment\n    return storage.Save(filename, content, config)\n}\n```\n\nAnd you\u0027ll need to update any code that calls `SaveAttachment` to include the storage configuration. For example:\n\n```go\n// For file storage:\nstorageConfig :\u003d StorageConfig{\n    Type: StorageTypeFile,\n}\n\n// For Google Drive storage:\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;/path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Call SaveAttachment with the new parameters\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```\n\nThe main changes are:\n1. Added context.Context parameter for Google Drive API\n2. Added StorageConfig parameter to specify the storage type and its configuration\n3. Using the new factory method `NewStorage` instead of directly creating `FileStorage`\n4. Improved error handling to include storage initialization errors\n\nThis change makes the storage backend configurable while maintaining the existing attachment processing logic.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// StorageConfig holds configuration for storage\ntype StorageConfig struct {\n\tType            string\n\tCredentialsFile string\n\tParentFolderID  string\n}\n\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\t// Create storage instance based on configuration\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\n\t// Use the storage implementation to save the attachment\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nwe have now conflicting StorageConfig\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;Yes, we have two different `StorageConfig` definitions. Let\u0027s consolidate them into a single definition in `storage.go` since that\u0027s where we define our storage interfaces and types:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen we need to remove the `StorageConfig` definition from `attachments.go`. The example usage would now look like:\n\n```go\n// Create storage configuration for file storage\nstorageConfig :\u003d StorageConfig{\n    Type: StorageTypeFile,\n}\n\n// Or for Google Drive storage\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeGDrive,\n    CredentialsFile: \&quot;/path/to/credentials.json\&quot;,\n    ParentFolderID:  \&quot;google_drive_folder_id\&quot;,\n}\n\n// Use in SaveAttachment\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```\n\nThe changes:\n1. Moved all storage-related types to `storage.go`\n2. Removed duplicate `StorageConfig` from `attachments.go`\n3. Added proper type for storage type using `StorageType` enum\n4. Consolidated all storage-related code in one place\n\nThis makes the code more organized and prevents type conflicts.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/attachments.go\n```go:internal/email/attachment/attachments.go\npackage attachment\n\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;\n\t\&quot;encoding/base64\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;io\&quot;\n\t\&quot;log/slog\&quot;\n\t\&quot;math/rand\&quot;\n\t\&quot;mime\&quot;\n\t\&quot;mime/quotedprintable\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;github.com/DusanKasan/parsemail\&quot;\n\t\&quot;github.com/jhillyerd/enmime/mediatype\&quot;\n)\n\n// ExtractAttachmentsMultipart extracts attachments from multipart content\nfunc ExtractAttachmentsMultipart(content []byte, boundary string, logger *slog.Logger) ([]parsemail.Attachment, error) {\n\t// Skip preamble and find first boundary\n\tboundaryBytes :\u003d []byte(\&quot;--\&quot; + boundary)\n\tif idx :\u003d bytes.Index(content, boundaryBytes); idx !\u003d -1 {\n\t\tcontent \u003d content[idx:]\n\t}\n\n\t// Function to handle nested multipart content\n\tvar handleMultipart func([]byte, string) ([]parsemail.Attachment, error)\n\thandleMultipart \u003d func(content []byte, boundary string) ([]parsemail.Attachment, error) {\n\t\tvar nestedAttachments []parsemail.Attachment\n\t\tvar currentPart []byte\n\t\tvar inHeader bool \u003d true\n\t\tvar headers map[string][]string \u003d make(map[string][]string)\n\n\t\tparts :\u003d bytes.Split(content, boundaryBytes)\n\t\tfor _, part :\u003d range parts[1:] { // Skip the first empty part\n\t\t\tif bytes.HasPrefix(part, []byte(\&quot;--\&quot;)) {\n\t\t\t\tbreak // End boundary\n\t\t\t}\n\n\t\t\t// Split headers and body\n\t\t\tlines :\u003d bytes.Split(bytes.TrimSpace(part), []byte(\&quot;\\n\&quot;))\n\t\t\tinHeader \u003d true\n\t\t\theaders \u003d make(map[string][]string)\n\t\t\tcurrentPart \u003d nil\n\t\t\tvar bodyStart int\n\n\t\t\tfor i, line :\u003d range lines {\n\t\t\t\tline \u003d bytes.TrimSpace(line)\n\t\t\t\tif len(line) \u003d\u003d 0 {\n\t\t\t\t\tinHeader \u003d false\n\t\t\t\t\tbodyStart \u003d i + 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif inHeader {\n\t\t\t\t\tif idx :\u003d bytes.Index(line, []byte(\&quot;:\&quot;)); idx \u003e 0 {\n\t\t\t\t\t\tkey :\u003d string(bytes.TrimSpace(line[:idx]))\n\t\t\t\t\t\tvalue :\u003d string(bytes.TrimSpace(line[idx+1:]))\n\t\t\t\t\t\theaders[key] \u003d append(headers[key], value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Join body lines with original line endings\n\t\t\tif bodyStart \u003c len(lines) {\n\t\t\t\tcurrentPart \u003d bytes.Join(lines[bodyStart:], []byte(\&quot;\\n\&quot;))\n\t\t\t}\n\n\t\t\t// Process the part based on headers\n\t\t\tcontentType :\u003d \&quot;\&quot;\n\t\t\tif ct, ok :\u003d headers[\&quot;Content-Type\&quot;]; ok \u0026\u0026 len(ct) \u003e 0 {\n\t\t\t\tcontentType \u003d ct[0]\n\t\t\t}\n\n\t\t\tmediaType, params, invalidParams, err :\u003d mediatype.Parse(contentType)\n\t\t\tlogger.Debug(\&quot;mediaType\&quot;, \&quot;mediaType\&quot;, mediaType, \&quot;params\&quot;, params, \&quot;invalidParams\&quot;, invalidParams, \&quot;err\&quot;, err)\n\t\t\tif err \u003d\u003d nil {\n\t\t\t\t// Handle nested multipart\n\t\t\t\tif strings.Contains(strings.ToLower(mediaType), \&quot;multipart\&quot;) {\n\t\t\t\t\tif nestedBoundary :\u003d params[\&quot;boundary\&quot;]; nestedBoundary !\u003d \&quot;\&quot; {\n\t\t\t\t\t\t// Clean up nested content before processing\n\t\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;--\&quot;+nestedBoundary)); idx !\u003d -1 {\n\t\t\t\t\t\t\tcurrentPart \u003d currentPart[idx:]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnested, err :\u003d handleMultipart(currentPart, nestedBoundary)\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, nested...)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Check for attachment\n\t\t\t\tcontentDisp :\u003d \&quot;\&quot;\n\t\t\t\tif cd, ok :\u003d headers[\&quot;Content-Disposition\&quot;]; ok \u0026\u0026 len(cd) \u003e 0 {\n\t\t\t\t\tcontentDisp \u003d cd[0]\n\t\t\t\t}\n\n\t\t\t\tfilename :\u003d \&quot;\&quot;\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tif _, params, _, err :\u003d mediatype.Parse(contentDisp); err \u003d\u003d nil {\n\t\t\t\t\t\tif fn, ok :\u003d params[\&quot;filename\&quot;]; ok {\n\t\t\t\t\t\t\tfilename \u003d DecodeFilename(fn)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If no filename from disposition, try Content-Type name parameter\n\t\t\t\tif filename \u003d\u003d \&quot;\&quot; \u0026\u0026 params[\&quot;name\&quot;] !\u003d \&quot;\&quot; {\n\t\t\t\t\tfilename \u003d DecodeFilename(params[\&quot;name\&quot;])\n\t\t\t\t}\n\n\t\t\t\t// Determine if this part is an attachment\n\t\t\t\tisAttachment :\u003d false\n\t\t\t\tif contentDisp !\u003d \&quot;\&quot; {\n\t\t\t\t\tisAttachment \u003d strings.Contains(contentDisp, \&quot;attachment\&quot;) || strings.Contains(contentDisp, \&quot;inline\&quot;)\n\t\t\t\t} else {\n\t\t\t\t\tisAttachment \u003d strings.HasPrefix(mediaType, \&quot;application/\&quot;) ||\n\t\t\t\t\t\tstrings.HasPrefix(mediaType, \&quot;image/\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;pdf\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;xml\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;msword\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;excel\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;spreadsheet\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;document\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;text\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;audio\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;video\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;application\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;zip\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;tar\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;gz\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;bz2\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;7z\&quot;) ||\n\t\t\t\t\t\tstrings.Contains(mediaType, \&quot;rar\&quot;)\n\t\t\t\t}\n\n\t\t\t\tif isAttachment \u0026\u0026 len(currentPart) \u003e 0 {\n\t\t\t\t\t// Trim any trailing boundary markers\n\t\t\t\t\tif idx :\u003d bytes.Index(currentPart, []byte(\&quot;\\n--\&quot;)); idx !\u003d -1 {\n\t\t\t\t\t\tcurrentPart \u003d currentPart[:idx]\n\t\t\t\t\t}\n\n\t\t\t\t\t// Handle content encoding\n\t\t\t\t\tif ce, ok :\u003d headers[\&quot;Content-Transfer-Encoding\&quot;]; ok \u0026\u0026 len(ce) \u003e 0 {\n\t\t\t\t\t\tdecoded, err :\u003d DecodeContent(currentPart, ce[0])\n\t\t\t\t\t\tif err \u003d\u003d nil {\n\t\t\t\t\t\t\tcurrentPart \u003d decoded\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Generate filename if needed\n\t\t\t\t\tif filename \u003d\u003d \&quot;\&quot; {\n\t\t\t\t\t\text :\u003d \&quot;.bin\&quot;\n\t\t\t\t\t\tif mimeExt, ok :\u003d MimeToExt[mediaType]; ok {\n\t\t\t\t\t\t\text \u003d mimeExt\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Just use a simple base name for attachments without names\n\t\t\t\t\t\tfilename \u003d fmt.Sprintf(\&quot;attachment%s\&quot;, ext)\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// For existing filenames, just trim spaces\n\t\t\t\t\t\tfilename \u003d strings.TrimSpace(filename)\n\t\t\t\t\t}\n\n\t\t\t\t\tnestedAttachments \u003d append(nestedAttachments, parsemail.Attachment{\n\t\t\t\t\t\tFilename: filename,\n\t\t\t\t\t\tData:     bytes.NewReader(currentPart),\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nestedAttachments, nil\n\t}\n\n\tlogger.Debug(\&quot;starting multipart extraction\&quot;, \&quot;boundary\&quot;, boundary)\n\treturn handleMultipart(content, boundary)\n}\n\n// DecodeContent decodes content based on the specified encoding\nfunc DecodeContent(content []byte, encoding string) ([]byte, error) {\n\tswitch strings.ToLower(encoding) {\n\tcase \&quot;base64\&quot;:\n\t\tdecoded :\u003d make([]byte, base64.StdEncoding.DecodedLen(len(content)))\n\t\tn, err :\u003d base64.StdEncoding.Decode(decoded, content)\n\t\tif err !\u003d nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn decoded[:n], nil\n\n\tcase \&quot;quoted-printable\&quot;:\n\t\treader :\u003d quotedprintable.NewReader(bytes.NewReader(content))\n\t\treturn io.ReadAll(reader)\n\n\tcase \&quot;7bit\&quot;, \&quot;8bit\&quot;, \&quot;binary\&quot;, \&quot;\&quot;:\n\t\treturn content, nil\n\n\tdefault:\n\t\treturn content, nil\n\t}\n}\n\n// DecodeFilename decodes RFC 2047 encoded-word syntax in filenames\nfunc DecodeFilename(filename string) string {\n\tdecoder :\u003d mime.WordDecoder{}\n\tdecoded, err :\u003d decoder.DecodeHeader(filename)\n\tif err !\u003d nil {\n\t\t// If decoding fails, return the original filename\n\t\treturn filename\n\t}\n\treturn decoded\n}\n\n// ParseEmail parses an email with fallback mechanisms\nfunc ParseEmail(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\tvar email parsemail.Email\n\tvar err error\n\n\t// Try to parse the email\n\temail, err \u003d parsemail.Parse(bytes.NewReader(content))\n\tif err !\u003d nil {\n\t\t// Check for specific error types\n\t\tif strings.Contains(err.Error(), \&quot;multipart: NextPart: EOF\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling multipart EOF error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for malformed multipart messages\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t} else if strings.Contains(err.Error(), \&quot;mime: invalid media parameter\&quot;) {\n\t\t\tlogger.Debug(\&quot;handling invalid media parameter error, attempting fallback parsing\&quot;)\n\t\t\t// Try fallback parsing method for invalid MIME parameters\n\t\t\treturn ParseEmailFallback(content, logger)\n\t\t}\n\t\treturn email, err\n\t}\n\n\treturn email, nil\n}\n\n// ParseEmailFallback provides a fallback method for parsing problematic emails\nfunc ParseEmailFallback(content []byte, logger *slog.Logger) (parsemail.Email, error) {\n\t// This would be your fallback implementation\n\t// For now, returning an empty email structure\n\treturn parsemail.Email{}, nil\n}\n\n// MimeToExt maps MIME types to file extensions\nvar MimeToExt \u003d map[string]string{\n\t\&quot;application/pdf\&quot;:          \&quot;.pdf\&quot;,\n\t\&quot;application/msword\&quot;:       \&quot;.doc\&quot;,\n\t\&quot;application/vnd.ms-excel\&quot;: \&quot;.xls\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;:   \&quot;.docx\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;:         \&quot;.xlsx\&quot;,\n\t\&quot;application/vnd.ms-powerpoint\&quot;:                                             \&quot;.ppt\&quot;,\n\t\&quot;application/vnd.openxmlformats-officedocument.presentationml.presentation\&quot;: \&quot;.pptx\&quot;,\n\t\&quot;image/jpeg\&quot;:                   \&quot;.jpg\&quot;,\n\t\&quot;image/png\&quot;:                    \&quot;.png\&quot;,\n\t\&quot;image/gif\&quot;:                    \&quot;.gif\&quot;,\n\t\&quot;image/bmp\&quot;:                    \&quot;.bmp\&quot;,\n\t\&quot;image/tiff\&quot;:                   \&quot;.tiff\&quot;,\n\t\&quot;text/plain\&quot;:                   \&quot;.txt\&quot;,\n\t\&quot;text/html\&quot;:                    \&quot;.html\&quot;,\n\t\&quot;text/csv\&quot;:                     \&quot;.csv\&quot;,\n\t\&quot;text/xml\&quot;:                     \&quot;.xml\&quot;,\n\t\&quot;audio/mpeg\&quot;:                   \&quot;.mp3\&quot;,\n\t\&quot;audio/wav\&quot;:                    \&quot;.wav\&quot;,\n\t\&quot;video/mp4\&quot;:                    \&quot;.mp4\&quot;,\n\t\&quot;video/mpeg\&quot;:                   \&quot;.mpeg\&quot;,\n\t\&quot;video/quicktime\&quot;:              \&quot;.mov\&quot;,\n\t\&quot;application/zip\&quot;:              \&quot;.zip\&quot;,\n\t\&quot;application/x-tar\&quot;:            \&quot;.tar\&quot;,\n\t\&quot;application/x-gzip\&quot;:           \&quot;.gz\&quot;,\n\t\&quot;application/x-bzip2\&quot;:          \&quot;.bz2\&quot;,\n\t\&quot;application/x-7z-compressed\&quot;:  \&quot;.7z\&quot;,\n\t\&quot;application/x-rar-compressed\&quot;: \&quot;.rar\&quot;,\n}\n\n// IsAllowedAttachment checks if a file with the given filename is allowed based on its extension\nfunc IsAllowedAttachment(filename string, allowedTypes []string, logger *slog.Logger) bool {\n\tif filename \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;empty filename\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text :\u003d filepath.Ext(filename)\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tlogger.Debug(\&quot;no extension\&quot;, \&quot;filename\&quot;, filename)\n\t\treturn false\n\t}\n\n\text \u003d strings.ToLower(ext)\n\tlogger.Debug(\&quot;checking attachment\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;extension\&quot;, ext,\n\t\t\&quot;allowed_types\&quot;, allowedTypes)\n\n\tfor _, allowedType :\u003d range allowedTypes {\n\t\tallowedType \u003d strings.ToLower(allowedType)\n\t\t// Compare with and without dot\n\t\tif ext \u003d\u003d allowedType ||\n\t\t\text \u003d\u003d \&quot;.\&quot;+strings.TrimPrefix(allowedType, \&quot;.\&quot;) ||\n\t\t\tstrings.TrimPrefix(ext, \&quot;.\&quot;) \u003d\u003d strings.TrimPrefix(allowedType, \&quot;.\&quot;) {\n\t\t\tlogger.Debug(\&quot;allowed attachment\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\t\t\treturn true\n\t\t}\n\t}\n\n\tlogger.Debug(\&quot;attachment not allowed\&quot;, \&quot;filename\&quot;, filename, \&quot;extension\&quot;, ext)\n\treturn false\n}\n\n// AttachmentConfig holds configuration for attachment processing\ntype AttachmentConfig struct {\n\tStoragePath       string\n\tMaxSize           int64\n\tAllowedTypes      []string\n\tSanitizeFilenames bool\n\tPreserveStructure bool\n\tFilenamePattern   string\n\tAccountName       string\n}\n\n// SaveAttachment saves attachment content using the configured storage\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\t// Create storage instance based on configuration\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\n\t// Use the storage implementation to save the attachment\n\treturn storage.Save(filename, content, config)\n}\n\n// SanitizeFilename removes potentially dangerous characters from filenames\nfunc SanitizeFilename(filename string) string {\n\t// Remove any path components\n\tfilename \u003d filepath.Base(filename)\n\n\t// Replace potentially problematic characters\n\treplacer :\u003d strings.NewReplacer(\n\t\t\&quot;/\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\\\&quot;, \&quot;_\&quot;,\n\t\t\&quot;:\&quot;, \&quot;_\&quot;,\n\t\t\&quot;*\&quot;, \&quot;_\&quot;,\n\t\t\&quot;?\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\\&quot;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003c\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u003e\&quot;, \&quot;_\&quot;,\n\t\t\&quot;|\&quot;, \&quot;_\&quot;,\n\t\t\&quot;;\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0026\&quot;, \&quot;_\&quot;,\n\t\t\&quot;$\&quot;, \&quot;_\&quot;,\n\t\t\&quot;#\&quot;, \&quot;_\&quot;,\n\t\t\&quot;%\&quot;, \&quot;_\&quot;,\n\t\t\&quot;@\&quot;, \&quot;_\&quot;,\n\t\t\&quot;!\&quot;, \&quot;_\&quot;,\n\t\t\&quot;`\&quot;, \&quot;_\&quot;,\n\t\t\&quot;~\&quot;, \&quot;_\&quot;,\n\t\t\&quot;^\&quot;, \&quot;_\&quot;,\n\t\t\&quot;(\&quot;, \&quot;_\&quot;,\n\t\t\&quot;)\&quot;, \&quot;_\&quot;,\n\t\t\&quot;[\&quot;, \&quot;_\&quot;,\n\t\t\&quot;]\&quot;, \&quot;_\&quot;,\n\t\t\&quot;{\&quot;, \&quot;_\&quot;,\n\t\t\&quot;}\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\u0027\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\n\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\r\&quot;, \&quot;_\&quot;,\n\t\t\&quot;\\t\&quot;, \&quot;_\&quot;,\n\t)\n\tfilename \u003d replacer.Replace(filename)\n\n\t// Limit filename length\n\tconst maxLength \u003d 255\n\tif len(filename) \u003e maxLength {\n\t\text :\u003d filepath.Ext(filename)\n\t\tbase :\u003d filename[:maxLength-len(ext)]\n\t\tfilename \u003d base + ext\n\t}\n\n\treturn filename\n}\n\n// GenerateFilename applies a naming pattern to a filename\nfunc GenerateFilename(filename string, timestamp time.Time, pattern string) string {\n\tif pattern \u003d\u003d \&quot;\&quot; {\n\t\treturn filename\n\t}\n\n\t// Extract base name and extension\n\text :\u003d filepath.Ext(filename)\n\tbase :\u003d strings.TrimSuffix(filename, ext)\n\n\t// Apply pattern\n\tresult :\u003d pattern\n\tresult \u003d strings.ReplaceAll(result, \&quot;{filename}\&quot;, base)\n\tresult \u003d strings.ReplaceAll(result, \&quot;{ext}\&quot;, strings.TrimPrefix(ext, \&quot;.\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{date}\&quot;, timestamp.Format(\&quot;2006-01-02\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{time}\&quot;, timestamp.Format(\&quot;150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{datetime}\&quot;, timestamp.Format(\&quot;20060102_150405\&quot;))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{unixtime}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, timestamp.UnixNano()))\n\tresult \u003d strings.ReplaceAll(result, \&quot;{random}\&quot;, fmt.Sprintf(\&quot;%d\&quot;, rand.Intn(10000)))\n\n\t// If the pattern doesn\u0027t include the extension, add it\n\tif !strings.Contains(pattern, \&quot;{ext}\&quot;) \u0026\u0026 !strings.HasSuffix(result, ext) {\n\t\tresult +\u003d ext\n\t}\n\n\treturn result\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\nplease fix:\n\ninternal/email/attachment/storage.go:8:6: AttachmentStorage redeclared in this block\n        internal/email/attachment/filestorage.go:30:6: other declaration of AttachmentStorage\ninternal/email/attachment/storage.go:14:6: NewFileStorage redeclared in this block\n        internal/email/attachment/filestorage.go:53:6: other declaration of NewFileStorage\ninternal/email/attachment/storage.go:19:6: FileStorage redeclared in this block\n        internal/email/attachment/filestorage.go:48:6: other declaration of FileStorage\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;We need to consolidate the declarations since we have duplicate definitions across files. Let\u0027s update `storage.go` to contain all the interface and type definitions while removing them from other files:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) *FileStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen we should remove these declarations from `filestorage.go` and keep only the implementation:\n\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\n// Keep only the Save method and helper methods\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n    // ... existing implementation ...\n}\n\n// ... helper methods ...\n```\n\nAnd in `attachments.go`, update the `SaveAttachment` function to use the proper type:\n\n```go:internal/email/attachment/attachments.go\n// Update the existing StorageConfig reference to use StorageType\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n    // Create storage instance based on configuration\n    storage, err :\u003d NewStorage(ctx, storageConfig, logger)\n    if err !\u003d nil {\n        return \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n    }\n\n    // Use the storage implementation to save the attachment\n    return storage.Save(filename, content, config)\n}\n```\n\nThis reorganization:\n1. Consolidates all interface and type definitions in `storage.go`\n2. Removes duplicate declarations from other files\n3. Keeps implementation details in their respective files\n4. Maintains proper type safety with the `StorageType` enum\n\nThe code should now compile without any redeclaration errors while maintaining the same functionality.&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cadditional_data\u003e\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/filestorage.go\n```go:internal/email/attachment/filestorage.go\npackage attachment\n\nimport (\n\t\&quot;fmt\&quot;\n\t\&quot;net/http\&quot;\n\t\&quot;os\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n)\n\n// FileStorage implementation of Save to store attachments on disk\nfunc (fs *FileStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// First sanitize if configured (before pattern application)\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tfilename \u003d GenerateFilename(filename, time.Now().UTC(), config.FilenamePattern)\n\n\t// Ensure filename has correct extension\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tbaseFilename :\u003d strings.TrimSuffix(filename, ext)\n\n\t// If the extension is uppercase, convert it to lowercase\n\tif ext !\u003d strings.ToLower(ext) {\n\t\tfilename \u003d baseFilename + strings.ToLower(ext)\n\t}\n\n\t// If no extension, try to detect from content\n\tif ext \u003d\u003d \&quot;\&quot; {\n\t\tcontentType :\u003d http.DetectContentType(content)\n\t\tif mimeExt, ok :\u003d MimeToExt[contentType]; ok {\n\t\t\tfilename \u003d filename + mimeExt\n\t\t\text \u003d mimeExt\n\t\t}\n\t}\n\n\t// Sanitize filename if configured\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Process storage path with date variables\n\tnow :\u003d time.Now().UTC()\n\tstoragePath :\u003d config.StoragePath\n\n\t// Check if the storage path contains variables\n\thasVars :\u003d strings.Contains(storagePath, \&quot;${\&quot;)\n\n\tfs.logger.Debug(\&quot;processing storage path\&quot;,\n\t\t\&quot;original\&quot;, storagePath,\n\t\t\&quot;has_vars\&quot;, hasVars,\n\t\t\&quot;account\&quot;, config.AccountName)\n\n\t// Replace variables in storage path\n\tif hasVars {\n\t\tstoragePath \u003d fs.processStoragePath(storagePath, now, config.AccountName)\n\t}\n\n\t// Determine the final directory path\n\tfinalDir :\u003d fs.getFinalDirectory(storagePath, hasVars, config.PreserveStructure, now)\n\n\tfs.logger.Debug(\&quot;final directory path\&quot;,\n\t\t\&quot;final_dir\&quot;, finalDir)\n\n\t// Create the directory\n\tif err :\u003d os.MkdirAll(finalDir, 0755); err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create storage directory: %w\&quot;, err)\n\t}\n\n\t// Get final path and handle duplicates\n\tfinalPath :\u003d fs.getUniquePath(filepath.Join(finalDir, filename))\n\n\t// Create and write file\n\tif err :\u003d fs.writeFile(finalPath, content); err !\u003d nil {\n\t\treturn \&quot;\&quot;, err\n\t}\n\n\treturn finalPath, nil\n}\n\n// Helper methods for FileStorage\nfunc (fs *FileStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (fs *FileStorage) getFinalDirectory(storagePath string, hasVars, preserveStructure bool, now time.Time) string {\n\tif preserveStructure \u0026\u0026 !hasVars {\n\t\tdateDir :\u003d now.Format(\&quot;2006/01/02\&quot;)\n\t\treturn filepath.Join(storagePath, dateDir)\n\t}\n\treturn storagePath\n}\n\nfunc (fs *FileStorage) getUniquePath(path string) string {\n\tif _, err :\u003d os.Stat(path); err \u003d\u003d nil {\n\t\text :\u003d filepath.Ext(path)\n\t\tbase :\u003d strings.TrimSuffix(path, ext)\n\t\tpath \u003d fmt.Sprintf(\&quot;%s_%d%s\&quot;, base, time.Now().UnixNano(), ext)\n\t}\n\treturn path\n}\n\nfunc (fs *FileStorage) writeFile(path string, content []byte) error {\n\tf, err :\u003d os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)\n\tif err !\u003d nil {\n\t\treturn fmt.Errorf(\&quot;failed to create file: %w\&quot;, err)\n\t}\n\tdefer f.Close()\n\n\tif _, err :\u003d f.Write(content); err !\u003d nil {\n\t\tos.Remove(path) // Clean up on error\n\t\treturn fmt.Errorf(\&quot;failed to write file content: %w\&quot;, err)\n\t}\n\treturn nil\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/storage.go\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;log/slog\&quot;\n)\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\n\u003cespecially_relevant_code_snippet\u003e\ninternal/email/attachment/gdrive_storage.go\n```go:internal/email/attachment/gdrive_storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\n\t\&quot;log/slog\&quot;\n\t\&quot;path/filepath\&quot;\n\t\&quot;strings\&quot;\n\t\&quot;time\&quot;\n\n\t\&quot;google.golang.org/api/drive/v3\&quot;\n\t\&quot;google.golang.org/api/option\&quot;\n)\n\n// GDriveStorage implements AttachmentStorage for Google Drive\ntype GDriveStorage struct {\n\tlogger   *slog.Logger\n\tservice  *drive.Service\n\tparentID string // Google Drive folder ID where files will be stored\n}\n\n// NewGDriveStorage creates a new Google Drive storage instance\nfunc NewGDriveStorage(ctx context.Context, logger *slog.Logger, credentialsFile, parentFolderID string) (AttachmentStorage, error) {\n\tservice, err :\u003d drive.NewService(ctx, option.WithCredentialsFile(credentialsFile))\n\tif err !\u003d nil {\n\t\treturn nil, fmt.Errorf(\&quot;failed to create Drive client: %w\&quot;, err)\n\t}\n\n\treturn \u0026GDriveStorage{\n\t\tlogger:   logger,\n\t\tservice:  service,\n\t\tparentID: parentFolderID,\n\t}, nil\n}\n\n// Save implements AttachmentStorage.Save for Google Drive\nfunc (gd *GDriveStorage) Save(filename string, content []byte, config AttachmentConfig) (string, error) {\n\t// Validate content size\n\tif int64(len(content)) \u003e config.MaxSize {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;attachment size %d exceeds maximum allowed size %d\&quot;, len(content), config.MaxSize)\n\t}\n\n\t// Process filename\n\tif config.SanitizeFilenames {\n\t\tfilename \u003d SanitizeFilename(filename)\n\t}\n\n\t// Apply the naming pattern\n\tnow :\u003d time.Now().UTC()\n\tfilename \u003d GenerateFilename(filename, now, config.FilenamePattern)\n\n\t// Process storage path with date variables\n\tfolderPath :\u003d config.StoragePath\n\tif strings.Contains(folderPath, \&quot;${\&quot;) {\n\t\tfolderPath \u003d gd.processStoragePath(folderPath, now, config.AccountName)\n\t}\n\n\t// Create or get folder structure\n\tfolderID, err :\u003d gd.ensureFolderStructure(folderPath, config.PreserveStructure)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to ensure folder structure: %w\&quot;, err)\n\t}\n\n\t// Create file metadata\n\tfile :\u003d \u0026drive.File{\n\t\tName:     filename,\n\t\tParents:  []string{folderID},\n\t\tMimeType: gd.getMimeType(filename),\n\t}\n\n\t// Upload file\n\treader :\u003d strings.NewReader(string(content))\n\tuploadedFile, err :\u003d gd.service.Files.Create(file).Media(reader).Do()\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to upload file: %w\&quot;, err)\n\t}\n\n\tgd.logger.Debug(\&quot;file uploaded successfully\&quot;,\n\t\t\&quot;filename\&quot;, filename,\n\t\t\&quot;id\&quot;, uploadedFile.Id,\n\t\t\&quot;size\&quot;, len(content))\n\n\treturn uploadedFile.Id, nil\n}\n\n// Helper methods\n\nfunc (gd *GDriveStorage) processStoragePath(path string, now time.Time, accountName string) string {\n\treplacements :\u003d map[string]string{\n\t\t\&quot;${YYYY}\&quot;:    now.Format(\&quot;2006\&quot;),\n\t\t\&quot;${YY}\&quot;:      now.Format(\&quot;06\&quot;),\n\t\t\&quot;${MM}\&quot;:      now.Format(\&quot;01\&quot;),\n\t\t\&quot;${DD}\&quot;:      now.Format(\&quot;02\&quot;),\n\t\t\&quot;${HH}\&quot;:      now.Format(\&quot;15\&quot;),\n\t\t\&quot;${mm}\&quot;:      now.Format(\&quot;04\&quot;),\n\t\t\&quot;${ss}\&quot;:      now.Format(\&quot;05\&quot;),\n\t\t\&quot;${account}\&quot;: accountName,\n\t}\n\n\tfor pattern, replacement :\u003d range replacements {\n\t\tpath \u003d strings.ReplaceAll(path, pattern, replacement)\n\t}\n\n\treturn path\n}\n\nfunc (gd *GDriveStorage) ensureFolderStructure(path string, preserveStructure bool) (string, error) {\n\tif path \u003d\u003d \&quot;\&quot; {\n\t\treturn gd.parentID, nil\n\t}\n\n\tparts :\u003d strings.Split(filepath.Clean(path), string(filepath.Separator))\n\tcurrentParentID :\u003d gd.parentID\n\n\tfor _, part :\u003d range parts {\n\t\tif part \u003d\u003d \&quot;\&quot; {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Search for existing folder\n\t\tquery :\u003d fmt.Sprintf(\&quot;name \u003d \u0027%s\u0027 and \u0027%s\u0027 in parents and mimeType \u003d \u0027application/vnd.google-apps.folder\u0027 and trashed \u003d false\&quot;,\n\t\t\tpart, currentParentID)\n\n\t\tfileList, err :\u003d gd.service.Files.List().Q(query).Fields(\&quot;files(id)\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to search for folder: %w\&quot;, err)\n\t\t}\n\n\t\tif len(fileList.Files) \u003e 0 {\n\t\t\tcurrentParentID \u003d fileList.Files[0].Id\n\t\t\tcontinue\n\t\t}\n\n\t\t// Create new folder\n\t\tfolder :\u003d \u0026drive.File{\n\t\t\tName:     part,\n\t\t\tMimeType: \&quot;application/vnd.google-apps.folder\&quot;,\n\t\t\tParents:  []string{currentParentID},\n\t\t}\n\n\t\tcreatedFolder, err :\u003d gd.service.Files.Create(folder).Fields(\&quot;id\&quot;).Do()\n\t\tif err !\u003d nil {\n\t\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to create folder: %w\&quot;, err)\n\t\t}\n\n\t\tcurrentParentID \u003d createdFolder.Id\n\t}\n\n\treturn currentParentID, nil\n}\n\nfunc (gd *GDriveStorage) getMimeType(filename string) string {\n\text :\u003d strings.ToLower(filepath.Ext(filename))\n\tswitch ext {\n\tcase \&quot;.pdf\&quot;:\n\t\treturn \&quot;application/pdf\&quot;\n\tcase \&quot;.doc\&quot;:\n\t\treturn \&quot;application/msword\&quot;\n\tcase \&quot;.docx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.wordprocessingml.document\&quot;\n\tcase \&quot;.xls\&quot;:\n\t\treturn \&quot;application/vnd.ms-excel\&quot;\n\tcase \&quot;.xlsx\&quot;:\n\t\treturn \&quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\&quot;\n\tcase \&quot;.jpg\&quot;, \&quot;.jpeg\&quot;:\n\t\treturn \&quot;image/jpeg\&quot;\n\tcase \&quot;.png\&quot;:\n\t\treturn \&quot;image/png\&quot;\n\tdefault:\n\t\treturn \&quot;application/octet-stream\&quot;\n\t}\n}\n\n```\n\u003c/especially_relevant_code_snippet\u003e\n\u003c/additional_data\u003e\n\n\n\u003cuser_query\u003e\ninternal/email/attachment/attachments.go:324:114: undefined: StorageConfig\ninternal/email/attachment/attachments.go:326:18: undefined: NewStorage\nfix\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;The error occurs because we haven\u0027t properly imported or defined the storage types. Let\u0027s fix this by adding the necessary type definitions and functions to `storage.go`:\n\n```go:internal/email/attachment/storage.go\npackage attachment\n\nimport (\n\t\&quot;context\&quot;\n\t\&quot;fmt\&quot;\n\t\&quot;log/slog\&quot;\n)\n\n// StorageType represents the type of storage backend\ntype StorageType string\n\nconst (\n\tStorageTypeFile   StorageType \u003d \&quot;file\&quot;\n\tStorageTypeGDrive StorageType \u003d \&quot;gdrive\&quot;\n)\n\n// StorageConfig holds configuration for creating storage instances\ntype StorageConfig struct {\n\tType            StorageType\n\tCredentialsFile string // Path to Google Drive credentials JSON file\n\tParentFolderID  string // Google Drive folder ID where files will be stored\n}\n\n// AttachmentStorage defines the interface for storing attachments\ntype AttachmentStorage interface {\n\t// Save stores the attachment content and returns the final path/identifier or error\n\tSave(filename string, content []byte, config AttachmentConfig) (string, error)\n}\n\n// NewStorage creates a new storage instance based on the configuration\nfunc NewStorage(ctx context.Context, config StorageConfig, logger *slog.Logger) (AttachmentStorage, error) {\n\tswitch config.Type {\n\tcase StorageTypeFile:\n\t\treturn NewFileStorage(logger), nil\n\tcase StorageTypeGDrive:\n\t\treturn NewGDriveStorage(ctx, logger, config.CredentialsFile, config.ParentFolderID)\n\tdefault:\n\t\treturn nil, fmt.Errorf(\&quot;unsupported storage type: %s\&quot;, config.Type)\n\t}\n}\n\n// FileStorage implements AttachmentStorage for local filesystem\ntype FileStorage struct {\n\tlogger *slog.Logger\n}\n\n// NewFileStorage creates a new FileStorage instance\nfunc NewFileStorage(logger *slog.Logger) AttachmentStorage {\n\treturn \u0026FileStorage{logger: logger}\n}\n```\n\nThen in `attachments.go`, add `context` to the imports if it\u0027s not already there:\n\n```go:internal/email/attachment/attachments.go\nimport (\n\t\&quot;bytes\&quot;\n\t\&quot;context\&quot;  // Make sure this is included\n\t// ... other imports ...\n)\n\n// The SaveAttachment function should now compile correctly\nfunc SaveAttachment(ctx context.Context, filename string, content []byte, config AttachmentConfig, storageConfig StorageConfig, logger *slog.Logger) (string, error) {\n\tstorage, err :\u003d NewStorage(ctx, storageConfig, logger)\n\tif err !\u003d nil {\n\t\treturn \&quot;\&quot;, fmt.Errorf(\&quot;failed to initialize storage: %w\&quot;, err)\n\t}\n\treturn storage.Save(filename, content, config)\n}\n```\n\nThe code should now compile successfully since:\n1. `StorageConfig` is properly defined in `storage.go`\n2. `NewStorage` function is available from `storage.go`\n3. All necessary types and functions are in the same package\n4. The required imports are in place\n\nYou can use it like this:\n\n```go\nstorageConfig :\u003d StorageConfig{\n    Type:            StorageTypeFile, // or StorageTypeGDrive\n    CredentialsFile: \&quot;path/to/credentials.json\&quot;, // only needed for GDrive\n    ParentFolderID:  \&quot;folder_id\&quot;,               // only needed for GDrive\n}\n\npath, err :\u003d SaveAttachment(ctx, filename, content, attachmentConfig, storageConfig, logger)\n```&quot;},{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nexplain the code\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;The request was cancelled. Here is my cutoff response:\n&quot;}]}" />
        <entry key="c2995eaa-ffe7-43b7-8a30-eaade14bd7a1" value="{&quot;id&quot;:&quot;c2995eaa-ffe7-43b7-8a30-eaade14bd7a1&quot;,&quot;name&quot;:&quot;Suggesting Improvements&quot;,&quot;timestamp&quot;:1740463359367,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;\u003cuser_query\u003e\nsuggest improvements\n\u003c/user_query\u003e&quot;},{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;Here are some suggested improvements for your Go code:\n\n1. **Error Handling in Viper Bindings**:\n```go:cmd/server/main.go\n// ... existing code ...\nif err :\u003d viper.BindPFlag(\&quot;logging.level\&quot;, rootCmd.PersistentFlags().Lookup(\&quot;log-level\&quot;)); err !\u003d nil {\n    logger.Error(\&quot;failed to bind log-level flag\&quot;, \&quot;error\&quot;, err)\n}\n// Repeat similar error handling for other BindPFlag calls\n// ... existing code ...\n```\n\n2. **Config Loading Improvement**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc initConfig() {\n    // ... existing code ...\n    configs :\u003d config.GetEnabledConfigs()\n    if len(configs) \u003d\u003d 0 {\n        logger.Error(\&quot;no enabled configurations found\&quot;, \&quot;config_dir\&quot;, configDir)\n        os.Exit(1)\n    }\n    // ... existing code ...\n}\n// ... existing code ...\n```\n\n3. **Graceful Shutdown Improvements**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc run(cmd *cobra.Command, args []string) error {\n    // ... existing code ...\n    ctx, cancel :\u003d context.WithTimeout(context.Background(), 30*time.Second)\n    defer cancel()\n    \n    if err :\u003d app.Stop(ctx); err !\u003d nil {\n        logger.Error(\&quot;failed to stop application gracefully\&quot;, \&quot;error\&quot;, err)\n        return err\n    }\n    return nil\n}\n// ... existing code ...\n```\n\n4. **Documentation Comments**:\n```go:cmd/server/main.go\n// rootCmd represents the base command when called without any subcommands\nvar rootCmd \u003d \u0026cobra.Command{\n    // ... existing code ...\n}\n\n// initConfig reads in config file and ENV variables if set.\nfunc initConfig() {\n    // ... existing code ...\n}\n\n// run is the main execution function for the root command\nfunc run(cmd *cobra.Command, args []string) error {\n    // ... existing code ...\n}\n```\n\n5. **Configuration Validation**:\n```go:cmd/server/main.go\n// ... existing code ...\nfunc initConfig() {\n    // ... existing code ...\n    if configID !\u003d \&quot;\&quot; {\n        if cfg, err :\u003d config.GetConfig(configID); err \u003d\u003d nil {\n            if err :\u003d cfg.Validate(); err !\u003d nil {\n                logger.Error(\&quot;invalid configuration\&quot;, \&quot;config_id\&quot;, configID, \&quot;error\&quot;, err)\n                os.Exit(1)\n            }\n            // ... existing code ...\n// ... existing code ...\n```\n\nAdditional suggestions:\n- Add version flag (`--version`) using cobra\n- Implement structured logging consistently throughout\n- Add context.Context to application methods\n- Consider adding configuration reload capabilities (watch config files)\n- Add proper signal handling for SIGHUP (for config reload)\n- Implement health checks and readiness probes\n- Add more detailed command-line help text\n- Consider adding subcommands for various operations\n\nThese improvements would make your code more robust, maintainable, and production-ready. The changes focus on better error handling, documentation, graceful shutdown, and configuration management.&quot;}]}" />
      </map>
    </option>
  </component>
</project>